{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4966, 29)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('dataset.csv', encoding=\"utf-8-sig\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Title_Of_Page</th>\n",
       "      <th>URL</th>\n",
       "      <th>Lenght_Of_Title</th>\n",
       "      <th>Presence_of_Keyword_in_Title</th>\n",
       "      <th>Title_Starts_with_Keyword</th>\n",
       "      <th>Lenght_of_Url</th>\n",
       "      <th>Presence_Of_Keyword_In_Url</th>\n",
       "      <th>Domain_Name</th>\n",
       "      <th>...</th>\n",
       "      <th>Keyword_in_Description</th>\n",
       "      <th>Total_Images</th>\n",
       "      <th>Images_Without_Alt_Tags</th>\n",
       "      <th>Images_With_Alt_Tag</th>\n",
       "      <th>Keyword_in_Alt_Tags_of_Images</th>\n",
       "      <th>Total_Links</th>\n",
       "      <th>Internal_Links</th>\n",
       "      <th>External_Links</th>\n",
       "      <th>Presence_of_Internal_Link</th>\n",
       "      <th>Presence_of_External_Links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3366</th>\n",
       "      <td>tie</td>\n",
       "      <td>86.0</td>\n",
       "      <td>std::tie - cppreference.com</td>\n",
       "      <td>https://en.cppreference.com/w/cpp/utility/tupl...</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>en.cppreference.com</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4857</th>\n",
       "      <td>hair combs</td>\n",
       "      <td>91.0</td>\n",
       "      <td>Combs - Combs &amp; Brushes - Health &amp; Beauty</td>\n",
       "      <td>https://www.lattliv.com.pk/health-beauty/combs...</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>www.lattliv.com.pk</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>38</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>359</td>\n",
       "      <td>354</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3588</th>\n",
       "      <td>gown</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Indo Western Gowns For Women Online | Utsav Fa...</td>\n",
       "      <td>https://www.utsavfashion.com/indowestern/gowns</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>www.utsavfashion.com</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>30</td>\n",
       "      <td>379</td>\n",
       "      <td>367</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Keyword  Rank                                      Title_Of_Page  \\\n",
       "3366        tie   86.0                        std::tie - cppreference.com   \n",
       "4857  hair combs  91.0          Combs - Combs & Brushes - Health & Beauty   \n",
       "3588        gown   8.0  Indo Western Gowns For Women Online | Utsav Fa...   \n",
       "\n",
       "                                                    URL  Lenght_Of_Title  \\\n",
       "3366  https://en.cppreference.com/w/cpp/utility/tupl...               27   \n",
       "4857  https://www.lattliv.com.pk/health-beauty/combs...               41   \n",
       "3588     https://www.utsavfashion.com/indowestern/gowns               51   \n",
       "\n",
       "      Presence_of_Keyword_in_Title  Title_Starts_with_Keyword  Lenght_of_Url  \\\n",
       "3366                             0                          0             51   \n",
       "4857                             1                          0             65   \n",
       "3588                             0                          0             46   \n",
       "\n",
       "      Presence_Of_Keyword_In_Url           Domain_Name  ...  \\\n",
       "3366                           1   en.cppreference.com  ...   \n",
       "4857                           1    www.lattliv.com.pk  ...   \n",
       "3588                           1  www.utsavfashion.com  ...   \n",
       "\n",
       "      Keyword_in_Description  Total_Images  Images_Without_Alt_Tags  \\\n",
       "3366                       0             3                        3   \n",
       "4857                       0            48                       38   \n",
       "3588                       1            45                        0   \n",
       "\n",
       "      Images_With_Alt_Tag  Keyword_in_Alt_Tags_of_Images  Total_Links  \\\n",
       "3366                    0                              0            0   \n",
       "4857                   10                              0          359   \n",
       "3588                   45                             30          379   \n",
       "\n",
       "      Internal_Links  External_Links  Presence_of_Internal_Link  \\\n",
       "3366               0               0                          0   \n",
       "4857             354               5                          1   \n",
       "3588             367              12                          1   \n",
       "\n",
       "      Presence_of_External_Links  \n",
       "3366                           0  \n",
       "4857                           1  \n",
       "3588                           1  \n",
       "\n",
       "[3 rows x 29 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Keyword                           object\n",
       "Rank                             float64\n",
       "Title_Of_Page                     object\n",
       "URL                               object\n",
       "Lenght_Of_Title                    int64\n",
       "Presence_of_Keyword_in_Title       int64\n",
       "Title_Starts_with_Keyword          int64\n",
       "Lenght_of_Url                      int64\n",
       "Presence_Of_Keyword_In_Url         int64\n",
       "Domain_Name                       object\n",
       "No_of_H1_Tags                      int64\n",
       "Presence_of_Keyword_in_H1_Tag      int64\n",
       "No_of_H2_tags                      int64\n",
       "Presence_of_Keyword_in_H2_Tag      int64\n",
       "No_of_H3_Tags                      int64\n",
       "Presence_of_Keyword_in_H3_Tag      int64\n",
       "Content_Lenght                     int64\n",
       "Keyword_Denisty                  float64\n",
       "Lenght_of_Description              int64\n",
       "Keyword_in_Description             int64\n",
       "Total_Images                       int64\n",
       "Images_Without_Alt_Tags            int64\n",
       "Images_With_Alt_Tag                int64\n",
       "Keyword_in_Alt_Tags_of_Images      int64\n",
       "Total_Links                        int64\n",
       "Internal_Links                     int64\n",
       "External_Links                     int64\n",
       "Presence_of_Internal_Link          int64\n",
       "Presence_of_External_Links         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2.])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "df['class'] = (df['Rank'] / 10).apply(np.ceil)\n",
    "df['class'] = df['class'] - 1\n",
    "df['class'] = np.where(df['class'] > 1, 2, df['class'])\n",
    "df['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Keyword', 'Title_Of_Page', 'URL', 'Domain_Name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Lenght_Of_Title</th>\n",
       "      <th>Presence_of_Keyword_in_Title</th>\n",
       "      <th>Title_Starts_with_Keyword</th>\n",
       "      <th>Lenght_of_Url</th>\n",
       "      <th>Presence_Of_Keyword_In_Url</th>\n",
       "      <th>No_of_H1_Tags</th>\n",
       "      <th>Presence_of_Keyword_in_H1_Tag</th>\n",
       "      <th>No_of_H2_tags</th>\n",
       "      <th>Presence_of_Keyword_in_H2_Tag</th>\n",
       "      <th>...</th>\n",
       "      <th>Total_Images</th>\n",
       "      <th>Images_Without_Alt_Tags</th>\n",
       "      <th>Images_With_Alt_Tag</th>\n",
       "      <th>Keyword_in_Alt_Tags_of_Images</th>\n",
       "      <th>Total_Links</th>\n",
       "      <th>Internal_Links</th>\n",
       "      <th>External_Links</th>\n",
       "      <th>Presence_of_Internal_Link</th>\n",
       "      <th>Presence_of_External_Links</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>26.0</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>116</td>\n",
       "      <td>17</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>184</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>4.0</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>343</td>\n",
       "      <td>335</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>9.0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>87</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3439</th>\n",
       "      <td>59.0</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323</th>\n",
       "      <td>35.0</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>49</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>435</td>\n",
       "      <td>429</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>32.0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>62</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>32.0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>4</td>\n",
       "      <td>172</td>\n",
       "      <td>152</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2871</th>\n",
       "      <td>89.0</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>180</td>\n",
       "      <td>66</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>205</td>\n",
       "      <td>185</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3950</th>\n",
       "      <td>74.0</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3810</th>\n",
       "      <td>32.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rank  Lenght_Of_Title  Presence_of_Keyword_in_Title  \\\n",
       "1117  26.0               64                             1   \n",
       "2188   4.0               62                             1   \n",
       "1100   9.0               29                             0   \n",
       "3439  59.0               60                             1   \n",
       "1323  35.0               36                             1   \n",
       "1220  32.0               30                             1   \n",
       "1420  32.0               28                             1   \n",
       "2871  89.0               63                             1   \n",
       "3950  74.0               52                             1   \n",
       "3810  32.0               40                             1   \n",
       "\n",
       "      Title_Starts_with_Keyword  Lenght_of_Url  Presence_Of_Keyword_In_Url  \\\n",
       "1117                          0             54                           1   \n",
       "2188                          1             31                           1   \n",
       "1100                          0             54                           1   \n",
       "3439                          1             95                           1   \n",
       "1323                          1             38                           0   \n",
       "1220                          1             50                           1   \n",
       "1420                          1             54                           1   \n",
       "2871                          1             55                           1   \n",
       "3950                          1             21                           0   \n",
       "3810                          1             74                           1   \n",
       "\n",
       "      No_of_H1_Tags  Presence_of_Keyword_in_H1_Tag  No_of_H2_tags  \\\n",
       "1117              1                              1              1   \n",
       "2188              1                              1              3   \n",
       "1100              2                              0              0   \n",
       "3439              1                              1              7   \n",
       "1323              1                              1              0   \n",
       "1220              1                              1              1   \n",
       "1420              1                              1             11   \n",
       "2871              4                              1             48   \n",
       "3950              0                              0              0   \n",
       "3810              1                              0              0   \n",
       "\n",
       "      Presence_of_Keyword_in_H2_Tag  ...  Total_Images  \\\n",
       "1117                              1  ...           116   \n",
       "2188                              1  ...            13   \n",
       "1100                              0  ...            13   \n",
       "3439                              1  ...             9   \n",
       "1323                              0  ...            76   \n",
       "1220                              0  ...             2   \n",
       "1420                              0  ...            63   \n",
       "2871                              0  ...           180   \n",
       "3950                              0  ...            21   \n",
       "3810                              0  ...             2   \n",
       "\n",
       "      Images_Without_Alt_Tags  Images_With_Alt_Tag  \\\n",
       "1117                       17                   99   \n",
       "2188                        2                   11   \n",
       "1100                        1                   12   \n",
       "3439                        0                    9   \n",
       "1323                       49                   27   \n",
       "1220                        1                    1   \n",
       "1420                        2                   61   \n",
       "2871                       66                  114   \n",
       "3950                       19                    2   \n",
       "3810                        2                    0   \n",
       "\n",
       "      Keyword_in_Alt_Tags_of_Images  Total_Links  Internal_Links  \\\n",
       "1117                              0          190             184   \n",
       "2188                             11          343             335   \n",
       "1100                              0           99              87   \n",
       "3439                              2           33              30   \n",
       "1323                              2          435             429   \n",
       "1220                              0           69              62   \n",
       "1420                              4          172             152   \n",
       "2871                              0          205             185   \n",
       "3950                              0           48              46   \n",
       "3810                              0            0               0   \n",
       "\n",
       "      External_Links  Presence_of_Internal_Link  Presence_of_External_Links  \\\n",
       "1117               6                          1                           1   \n",
       "2188               8                          1                           1   \n",
       "1100              12                          1                           1   \n",
       "3439               3                          1                           1   \n",
       "1323               6                          1                           1   \n",
       "1220               7                          1                           1   \n",
       "1420              20                          1                           1   \n",
       "2871              20                          1                           1   \n",
       "3950               2                          1                           1   \n",
       "3810               0                          0                           0   \n",
       "\n",
       "      class  \n",
       "1117    2.0  \n",
       "2188    0.0  \n",
       "1100    0.0  \n",
       "3439    2.0  \n",
       "1323    2.0  \n",
       "1220    2.0  \n",
       "1420    2.0  \n",
       "2871    2.0  \n",
       "3950    2.0  \n",
       "3810    2.0  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2.])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=['Rank', 'class'])\n",
    "y = df['class']\n",
    "y.unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding\n",
    "#### HotEncoder introduce Dummy variables (and that shall include only 0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder =  LabelEncoder()\n",
    "y1 = encoder.fit_transform(y)\n",
    "Y = pd.get_dummies(y1).values\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train = sc.transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 24)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3476, 24)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rank                             0\n",
       "Lenght_Of_Title                  0\n",
       "Presence_of_Keyword_in_Title     0\n",
       "Title_Starts_with_Keyword        0\n",
       "Lenght_of_Url                    0\n",
       "Presence_Of_Keyword_In_Url       0\n",
       "No_of_H1_Tags                    0\n",
       "Presence_of_Keyword_in_H1_Tag    0\n",
       "No_of_H2_tags                    0\n",
       "Presence_of_Keyword_in_H2_Tag    0\n",
       "No_of_H3_Tags                    0\n",
       "Presence_of_Keyword_in_H3_Tag    0\n",
       "Content_Lenght                   0\n",
       "Keyword_Denisty                  0\n",
       "Lenght_of_Description            0\n",
       "Keyword_in_Description           0\n",
       "Total_Images                     0\n",
       "Images_Without_Alt_Tags          0\n",
       "Images_With_Alt_Tag              0\n",
       "Keyword_in_Alt_Tags_of_Images    0\n",
       "Total_Links                      0\n",
       "Internal_Links                   0\n",
       "External_Links                   0\n",
       "Presence_of_Internal_Link        0\n",
       "Presence_of_External_Links       0\n",
       "class                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialising the Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "# !pip install keras\n",
    "# !pip install tensorflow\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer\n",
    "model.add(Dense(24,input_shape=(24,), activation='relu'))\n",
    "# Adding the output layer\n",
    "model.add(Dense(3, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the ANN\n",
    "#### adam is implemenation version of stocahastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"Adam\", loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the ANN to the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.8885 - accuracy: 0.6934\n",
      "Epoch 2/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.6740 - accuracy: 0.7935\n",
      "Epoch 3/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.6667 - accuracy: 0.7920\n",
      "Epoch 4/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.6552 - accuracy: 0.7896\n",
      "Epoch 5/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.6382 - accuracy: 0.7941\n",
      "Epoch 6/1000\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.6247 - accuracy: 0.7948\n",
      "Epoch 7/1000\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.6072 - accuracy: 0.8076\n",
      "Epoch 8/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.6017 - accuracy: 0.8036\n",
      "Epoch 9/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.6138 - accuracy: 0.7963\n",
      "Epoch 10/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.6075 - accuracy: 0.7964\n",
      "Epoch 11/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.6164 - accuracy: 0.7919\n",
      "Epoch 12/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.6162 - accuracy: 0.7912\n",
      "Epoch 13/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.6054 - accuracy: 0.7930\n",
      "Epoch 14/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.6240 - accuracy: 0.7864\n",
      "Epoch 15/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5926 - accuracy: 0.7985\n",
      "Epoch 16/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.6086 - accuracy: 0.7962\n",
      "Epoch 17/1000\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.6040 - accuracy: 0.7961\n",
      "Epoch 18/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5740 - accuracy: 0.8117\n",
      "Epoch 19/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5926 - accuracy: 0.8042\n",
      "Epoch 20/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5896 - accuracy: 0.8025\n",
      "Epoch 21/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.6157 - accuracy: 0.7964\n",
      "Epoch 22/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.6204 - accuracy: 0.7858\n",
      "Epoch 23/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.6060 - accuracy: 0.7902\n",
      "Epoch 24/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5910 - accuracy: 0.7965\n",
      "Epoch 25/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5906 - accuracy: 0.7981\n",
      "Epoch 26/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5885 - accuracy: 0.7972\n",
      "Epoch 27/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5894 - accuracy: 0.8007\n",
      "Epoch 28/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5823 - accuracy: 0.8032\n",
      "Epoch 29/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5891 - accuracy: 0.7983\n",
      "Epoch 30/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5936 - accuracy: 0.7956\n",
      "Epoch 31/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5677 - accuracy: 0.8114\n",
      "Epoch 32/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5864 - accuracy: 0.8016\n",
      "Epoch 33/1000\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.5909 - accuracy: 0.7952\n",
      "Epoch 34/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5941 - accuracy: 0.7957\n",
      "Epoch 35/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5693 - accuracy: 0.8017\n",
      "Epoch 36/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5406 - accuracy: 0.8136\n",
      "Epoch 37/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5978 - accuracy: 0.7955\n",
      "Epoch 38/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5928 - accuracy: 0.7936\n",
      "Epoch 39/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5963 - accuracy: 0.7956\n",
      "Epoch 40/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5590 - accuracy: 0.8097\n",
      "Epoch 41/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5708 - accuracy: 0.8058\n",
      "Epoch 42/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5757 - accuracy: 0.8021\n",
      "Epoch 43/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5808 - accuracy: 0.8049\n",
      "Epoch 44/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5478 - accuracy: 0.8131\n",
      "Epoch 45/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5831 - accuracy: 0.7932\n",
      "Epoch 46/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5812 - accuracy: 0.7932\n",
      "Epoch 47/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5465 - accuracy: 0.8152\n",
      "Epoch 48/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5604 - accuracy: 0.8082\n",
      "Epoch 49/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5566 - accuracy: 0.8104\n",
      "Epoch 50/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5589 - accuracy: 0.8036\n",
      "Epoch 51/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5570 - accuracy: 0.8061\n",
      "Epoch 52/1000\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.5582 - accuracy: 0.8068\n",
      "Epoch 53/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5708 - accuracy: 0.8025\n",
      "Epoch 54/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5843 - accuracy: 0.7934\n",
      "Epoch 55/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5575 - accuracy: 0.8028\n",
      "Epoch 56/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5705 - accuracy: 0.8029\n",
      "Epoch 57/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5633 - accuracy: 0.8048\n",
      "Epoch 58/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5839 - accuracy: 0.7921\n",
      "Epoch 59/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5610 - accuracy: 0.8044\n",
      "Epoch 60/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5672 - accuracy: 0.8028\n",
      "Epoch 61/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5487 - accuracy: 0.8084\n",
      "Epoch 62/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5585 - accuracy: 0.8122\n",
      "Epoch 63/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5734 - accuracy: 0.7986\n",
      "Epoch 64/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5681 - accuracy: 0.8017\n",
      "Epoch 65/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5435 - accuracy: 0.8156\n",
      "Epoch 66/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5549 - accuracy: 0.8100\n",
      "Epoch 67/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5480 - accuracy: 0.8067\n",
      "Epoch 68/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5639 - accuracy: 0.8066\n",
      "Epoch 69/1000\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.5600 - accuracy: 0.8020\n",
      "Epoch 70/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5600 - accuracy: 0.7982\n",
      "Epoch 71/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5470 - accuracy: 0.8074\n",
      "Epoch 72/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5547 - accuracy: 0.8109\n",
      "Epoch 73/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5390 - accuracy: 0.8113\n",
      "Epoch 74/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5423 - accuracy: 0.8135\n",
      "Epoch 75/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5446 - accuracy: 0.8110\n",
      "Epoch 76/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5343 - accuracy: 0.8124\n",
      "Epoch 77/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5477 - accuracy: 0.8135\n",
      "Epoch 78/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5465 - accuracy: 0.8079\n",
      "Epoch 79/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5423 - accuracy: 0.8089\n",
      "Epoch 80/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5583 - accuracy: 0.8049\n",
      "Epoch 81/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5359 - accuracy: 0.8156\n",
      "Epoch 82/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5301 - accuracy: 0.8149\n",
      "Epoch 83/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5417 - accuracy: 0.8094\n",
      "Epoch 84/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5387 - accuracy: 0.8113\n",
      "Epoch 85/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5545 - accuracy: 0.8063\n",
      "Epoch 86/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5249 - accuracy: 0.8207\n",
      "Epoch 87/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5447 - accuracy: 0.8026\n",
      "Epoch 88/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5579 - accuracy: 0.7999\n",
      "Epoch 89/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5454 - accuracy: 0.8101\n",
      "Epoch 90/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5421 - accuracy: 0.8046\n",
      "Epoch 91/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5244 - accuracy: 0.8174\n",
      "Epoch 92/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5215 - accuracy: 0.8158\n",
      "Epoch 93/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5142 - accuracy: 0.8206\n",
      "Epoch 94/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5404 - accuracy: 0.8099\n",
      "Epoch 95/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5505 - accuracy: 0.8062\n",
      "Epoch 96/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5263 - accuracy: 0.8186\n",
      "Epoch 97/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5615 - accuracy: 0.8043\n",
      "Epoch 98/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5151 - accuracy: 0.8226\n",
      "Epoch 99/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5473 - accuracy: 0.8026\n",
      "Epoch 100/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5702 - accuracy: 0.7976\n",
      "Epoch 101/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5303 - accuracy: 0.8092\n",
      "Epoch 102/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5545 - accuracy: 0.7969\n",
      "Epoch 103/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5433 - accuracy: 0.8042\n",
      "Epoch 104/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5497 - accuracy: 0.8030\n",
      "Epoch 105/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5349 - accuracy: 0.8094\n",
      "Epoch 106/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5299 - accuracy: 0.8167\n",
      "Epoch 107/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5512 - accuracy: 0.8033\n",
      "Epoch 108/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5060 - accuracy: 0.8237\n",
      "Epoch 109/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5438 - accuracy: 0.8122\n",
      "Epoch 110/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5166 - accuracy: 0.8212: 0s - loss: 0.5056 - \n",
      "Epoch 111/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5178 - accuracy: 0.8161\n",
      "Epoch 112/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5563 - accuracy: 0.7985\n",
      "Epoch 113/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5642 - accuracy: 0.7944\n",
      "Epoch 114/1000\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.5292 - accuracy: 0.8107\n",
      "Epoch 115/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5257 - accuracy: 0.8142\n",
      "Epoch 116/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5220 - accuracy: 0.8126\n",
      "Epoch 117/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5334 - accuracy: 0.8103\n",
      "Epoch 118/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5284 - accuracy: 0.8121\n",
      "Epoch 119/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5454 - accuracy: 0.8074\n",
      "Epoch 120/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5460 - accuracy: 0.8100\n",
      "Epoch 121/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5245 - accuracy: 0.8159\n",
      "Epoch 122/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5443 - accuracy: 0.8110\n",
      "Epoch 123/1000\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.5371 - accuracy: 0.8090\n",
      "Epoch 124/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5272 - accuracy: 0.8119\n",
      "Epoch 125/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5143 - accuracy: 0.8209\n",
      "Epoch 126/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5207 - accuracy: 0.8201\n",
      "Epoch 127/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5346 - accuracy: 0.8146\n",
      "Epoch 128/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5320 - accuracy: 0.8149\n",
      "Epoch 129/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5442 - accuracy: 0.8041\n",
      "Epoch 130/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5229 - accuracy: 0.8146\n",
      "Epoch 131/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5369 - accuracy: 0.8133\n",
      "Epoch 132/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5317 - accuracy: 0.8114\n",
      "Epoch 133/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5261 - accuracy: 0.8145\n",
      "Epoch 134/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5397 - accuracy: 0.8084\n",
      "Epoch 135/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5199 - accuracy: 0.8143\n",
      "Epoch 136/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5579 - accuracy: 0.8023\n",
      "Epoch 137/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5290 - accuracy: 0.8171\n",
      "Epoch 138/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5461 - accuracy: 0.7987\n",
      "Epoch 139/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5295 - accuracy: 0.8108\n",
      "Epoch 140/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5183 - accuracy: 0.8167\n",
      "Epoch 141/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5297 - accuracy: 0.8105\n",
      "Epoch 142/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5201 - accuracy: 0.8223\n",
      "Epoch 143/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5330 - accuracy: 0.8123\n",
      "Epoch 144/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5218 - accuracy: 0.8143\n",
      "Epoch 145/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5239 - accuracy: 0.8131\n",
      "Epoch 146/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5167 - accuracy: 0.8233\n",
      "Epoch 147/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4989 - accuracy: 0.8303\n",
      "Epoch 148/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5218 - accuracy: 0.8085\n",
      "Epoch 149/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5121 - accuracy: 0.8151\n",
      "Epoch 150/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5329 - accuracy: 0.8101\n",
      "Epoch 151/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5391 - accuracy: 0.8056\n",
      "Epoch 152/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5185 - accuracy: 0.8181\n",
      "Epoch 153/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5243 - accuracy: 0.8094\n",
      "Epoch 154/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5266 - accuracy: 0.8112\n",
      "Epoch 155/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5466 - accuracy: 0.7981\n",
      "Epoch 156/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5292 - accuracy: 0.8175\n",
      "Epoch 157/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5108 - accuracy: 0.8170\n",
      "Epoch 158/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5101 - accuracy: 0.8202\n",
      "Epoch 159/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5298 - accuracy: 0.8108\n",
      "Epoch 160/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5391 - accuracy: 0.8022\n",
      "Epoch 161/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5456 - accuracy: 0.8061\n",
      "Epoch 162/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5425 - accuracy: 0.8066\n",
      "Epoch 163/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5399 - accuracy: 0.8095\n",
      "Epoch 164/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5101 - accuracy: 0.8161\n",
      "Epoch 165/1000\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.5012 - accuracy: 0.8167\n",
      "Epoch 166/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5194 - accuracy: 0.8127\n",
      "Epoch 167/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5367 - accuracy: 0.8024\n",
      "Epoch 168/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5304 - accuracy: 0.8120\n",
      "Epoch 169/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5521 - accuracy: 0.7967\n",
      "Epoch 170/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5245 - accuracy: 0.8142\n",
      "Epoch 171/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5288 - accuracy: 0.8134\n",
      "Epoch 172/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5293 - accuracy: 0.8106\n",
      "Epoch 173/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5191 - accuracy: 0.8092\n",
      "Epoch 174/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5280 - accuracy: 0.8146\n",
      "Epoch 175/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5151 - accuracy: 0.8160\n",
      "Epoch 176/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5565 - accuracy: 0.8005\n",
      "Epoch 177/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5388 - accuracy: 0.8080\n",
      "Epoch 178/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5130 - accuracy: 0.8191\n",
      "Epoch 179/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5273 - accuracy: 0.8122\n",
      "Epoch 180/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5277 - accuracy: 0.8098\n",
      "Epoch 181/1000\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.5164 - accuracy: 0.8122\n",
      "Epoch 182/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5070 - accuracy: 0.8230\n",
      "Epoch 183/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5089 - accuracy: 0.8221\n",
      "Epoch 184/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5203 - accuracy: 0.8124\n",
      "Epoch 185/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5113 - accuracy: 0.8167\n",
      "Epoch 186/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5274 - accuracy: 0.8071\n",
      "Epoch 187/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5314 - accuracy: 0.8126\n",
      "Epoch 188/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5142 - accuracy: 0.8221\n",
      "Epoch 189/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5322 - accuracy: 0.8067\n",
      "Epoch 190/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5112 - accuracy: 0.8200\n",
      "Epoch 191/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5480 - accuracy: 0.8025\n",
      "Epoch 192/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5240 - accuracy: 0.8143\n",
      "Epoch 193/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5007 - accuracy: 0.8227\n",
      "Epoch 194/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5143 - accuracy: 0.8145\n",
      "Epoch 195/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5272 - accuracy: 0.8142\n",
      "Epoch 196/1000\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.5101 - accuracy: 0.8205\n",
      "Epoch 197/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5189 - accuracy: 0.8126\n",
      "Epoch 198/1000\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.5125 - accuracy: 0.8128\n",
      "Epoch 199/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5388 - accuracy: 0.8076\n",
      "Epoch 200/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5195 - accuracy: 0.8122\n",
      "Epoch 201/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5335 - accuracy: 0.8060\n",
      "Epoch 202/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5232 - accuracy: 0.8084\n",
      "Epoch 203/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5225 - accuracy: 0.8160\n",
      "Epoch 204/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5170 - accuracy: 0.8130\n",
      "Epoch 205/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5213 - accuracy: 0.8066: 0s - loss: 0.5206 - accuracy\n",
      "Epoch 206/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5380 - accuracy: 0.8145\n",
      "Epoch 207/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5049 - accuracy: 0.8156\n",
      "Epoch 208/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5057 - accuracy: 0.8208\n",
      "Epoch 209/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5162 - accuracy: 0.8160\n",
      "Epoch 210/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5069 - accuracy: 0.8253\n",
      "Epoch 211/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5274 - accuracy: 0.8086\n",
      "Epoch 212/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5301 - accuracy: 0.8058\n",
      "Epoch 213/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5229 - accuracy: 0.8167\n",
      "Epoch 214/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5235 - accuracy: 0.8139\n",
      "Epoch 215/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5178 - accuracy: 0.8148\n",
      "Epoch 216/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5351 - accuracy: 0.8139\n",
      "Epoch 217/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5133 - accuracy: 0.8152\n",
      "Epoch 218/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5182 - accuracy: 0.8159\n",
      "Epoch 219/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4869 - accuracy: 0.8289\n",
      "Epoch 220/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5173 - accuracy: 0.8123\n",
      "Epoch 221/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5274 - accuracy: 0.8044\n",
      "Epoch 222/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5024 - accuracy: 0.8229\n",
      "Epoch 223/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5198 - accuracy: 0.8150\n",
      "Epoch 224/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5259 - accuracy: 0.8111\n",
      "Epoch 225/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5210 - accuracy: 0.8072\n",
      "Epoch 226/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5173 - accuracy: 0.8223\n",
      "Epoch 227/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5306 - accuracy: 0.8122\n",
      "Epoch 228/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5078 - accuracy: 0.8145\n",
      "Epoch 229/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5284 - accuracy: 0.8040\n",
      "Epoch 230/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5190 - accuracy: 0.8111\n",
      "Epoch 231/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5136 - accuracy: 0.8152\n",
      "Epoch 232/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5442 - accuracy: 0.7994\n",
      "Epoch 233/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5176 - accuracy: 0.8177\n",
      "Epoch 234/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5076 - accuracy: 0.8161\n",
      "Epoch 235/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5203 - accuracy: 0.8160\n",
      "Epoch 236/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5209 - accuracy: 0.8074\n",
      "Epoch 237/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5048 - accuracy: 0.8232\n",
      "Epoch 238/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5166 - accuracy: 0.8126\n",
      "Epoch 239/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5406 - accuracy: 0.7952\n",
      "Epoch 240/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5278 - accuracy: 0.8024\n",
      "Epoch 241/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5206 - accuracy: 0.8102\n",
      "Epoch 242/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5158 - accuracy: 0.8128\n",
      "Epoch 243/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5072 - accuracy: 0.8197\n",
      "Epoch 244/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5194 - accuracy: 0.8037\n",
      "Epoch 245/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4946 - accuracy: 0.8274\n",
      "Epoch 246/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5126 - accuracy: 0.8156\n",
      "Epoch 247/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5273 - accuracy: 0.8108\n",
      "Epoch 248/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5230 - accuracy: 0.8049\n",
      "Epoch 249/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5126 - accuracy: 0.8114\n",
      "Epoch 250/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5179 - accuracy: 0.8156\n",
      "Epoch 251/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5554 - accuracy: 0.7936\n",
      "Epoch 252/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5232 - accuracy: 0.8055\n",
      "Epoch 253/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4750 - accuracy: 0.8291\n",
      "Epoch 254/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4996 - accuracy: 0.8183\n",
      "Epoch 255/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4997 - accuracy: 0.8189\n",
      "Epoch 256/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5164 - accuracy: 0.8120\n",
      "Epoch 257/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5354 - accuracy: 0.7973\n",
      "Epoch 258/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5077 - accuracy: 0.8184\n",
      "Epoch 259/1000\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.5118 - accuracy: 0.8166\n",
      "Epoch 260/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5127 - accuracy: 0.8173\n",
      "Epoch 261/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5108 - accuracy: 0.8162\n",
      "Epoch 262/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5051 - accuracy: 0.8165\n",
      "Epoch 263/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5179 - accuracy: 0.8186\n",
      "Epoch 264/1000\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.5130 - accuracy: 0.8186\n",
      "Epoch 265/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5212 - accuracy: 0.8080\n",
      "Epoch 266/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.8157\n",
      "Epoch 267/1000\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.5242 - accuracy: 0.8112\n",
      "Epoch 268/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5328 - accuracy: 0.8050\n",
      "Epoch 269/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5108 - accuracy: 0.8131\n",
      "Epoch 270/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5092 - accuracy: 0.8163\n",
      "Epoch 271/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5291 - accuracy: 0.8010\n",
      "Epoch 272/1000\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.4822 - accuracy: 0.8314\n",
      "Epoch 273/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5084 - accuracy: 0.8049\n",
      "Epoch 274/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5123 - accuracy: 0.8115\n",
      "Epoch 275/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5220 - accuracy: 0.8062\n",
      "Epoch 276/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4998 - accuracy: 0.8217\n",
      "Epoch 277/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4997 - accuracy: 0.8237\n",
      "Epoch 278/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5285 - accuracy: 0.8074\n",
      "Epoch 279/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.4993 - accuracy: 0.8151\n",
      "Epoch 280/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.4964 - accuracy: 0.8244\n",
      "Epoch 281/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5057 - accuracy: 0.8175\n",
      "Epoch 282/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5192 - accuracy: 0.8098\n",
      "Epoch 283/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5166 - accuracy: 0.8129\n",
      "Epoch 284/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5205 - accuracy: 0.8090\n",
      "Epoch 285/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5300 - accuracy: 0.8066\n",
      "Epoch 286/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.4994 - accuracy: 0.8210\n",
      "Epoch 287/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5056 - accuracy: 0.8124\n",
      "Epoch 288/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5035 - accuracy: 0.8104\n",
      "Epoch 289/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5244 - accuracy: 0.8001\n",
      "Epoch 290/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5194 - accuracy: 0.8124\n",
      "Epoch 291/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5041 - accuracy: 0.8199\n",
      "Epoch 292/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4886 - accuracy: 0.8257\n",
      "Epoch 293/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4933 - accuracy: 0.8173\n",
      "Epoch 294/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5060 - accuracy: 0.8143\n",
      "Epoch 295/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4933 - accuracy: 0.8232\n",
      "Epoch 296/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5105 - accuracy: 0.8168\n",
      "Epoch 297/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4929 - accuracy: 0.8210\n",
      "Epoch 298/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5167 - accuracy: 0.8144\n",
      "Epoch 299/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5103 - accuracy: 0.8153\n",
      "Epoch 300/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4987 - accuracy: 0.8216\n",
      "Epoch 301/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5358 - accuracy: 0.7993\n",
      "Epoch 302/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5123 - accuracy: 0.8135\n",
      "Epoch 303/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5013 - accuracy: 0.8124\n",
      "Epoch 304/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5074 - accuracy: 0.8130\n",
      "Epoch 305/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5173 - accuracy: 0.8141\n",
      "Epoch 306/1000\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.5155 - accuracy: 0.8132\n",
      "Epoch 307/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5146 - accuracy: 0.8120\n",
      "Epoch 308/1000\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.4939 - accuracy: 0.8144\n",
      "Epoch 309/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5278 - accuracy: 0.8038\n",
      "Epoch 310/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5038 - accuracy: 0.8096\n",
      "Epoch 311/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5002 - accuracy: 0.8175\n",
      "Epoch 312/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5143 - accuracy: 0.8097\n",
      "Epoch 313/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4880 - accuracy: 0.8250\n",
      "Epoch 314/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5008 - accuracy: 0.8199\n",
      "Epoch 315/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4983 - accuracy: 0.8180\n",
      "Epoch 316/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5064 - accuracy: 0.8158\n",
      "Epoch 317/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5235 - accuracy: 0.8053\n",
      "Epoch 318/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5261 - accuracy: 0.8044\n",
      "Epoch 319/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5034 - accuracy: 0.8160\n",
      "Epoch 320/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5119 - accuracy: 0.8109\n",
      "Epoch 321/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5180 - accuracy: 0.8095\n",
      "Epoch 322/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5044 - accuracy: 0.8100\n",
      "Epoch 323/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5351 - accuracy: 0.7980\n",
      "Epoch 324/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5243 - accuracy: 0.8073\n",
      "Epoch 325/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5243 - accuracy: 0.8136\n",
      "Epoch 326/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5139 - accuracy: 0.8123\n",
      "Epoch 327/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4949 - accuracy: 0.8186\n",
      "Epoch 328/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5037 - accuracy: 0.8171\n",
      "Epoch 329/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4703 - accuracy: 0.8297\n",
      "Epoch 330/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4746 - accuracy: 0.8310\n",
      "Epoch 331/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5076 - accuracy: 0.8149\n",
      "Epoch 332/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4808 - accuracy: 0.8236\n",
      "Epoch 333/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5053 - accuracy: 0.8184\n",
      "Epoch 334/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4959 - accuracy: 0.8285\n",
      "Epoch 335/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5195 - accuracy: 0.8115\n",
      "Epoch 336/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5052 - accuracy: 0.8187\n",
      "Epoch 337/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4873 - accuracy: 0.8285\n",
      "Epoch 338/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5127 - accuracy: 0.8139\n",
      "Epoch 339/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5007 - accuracy: 0.8211\n",
      "Epoch 340/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5021 - accuracy: 0.8161\n",
      "Epoch 341/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5051 - accuracy: 0.8186\n",
      "Epoch 342/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5129 - accuracy: 0.8142\n",
      "Epoch 343/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5025 - accuracy: 0.8166\n",
      "Epoch 344/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5073 - accuracy: 0.8152\n",
      "Epoch 345/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5071 - accuracy: 0.8152\n",
      "Epoch 346/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5048 - accuracy: 0.8176\n",
      "Epoch 347/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5230 - accuracy: 0.8039\n",
      "Epoch 348/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4991 - accuracy: 0.8170\n",
      "Epoch 349/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.8181\n",
      "Epoch 350/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5126 - accuracy: 0.8134\n",
      "Epoch 351/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5155 - accuracy: 0.8115\n",
      "Epoch 352/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4905 - accuracy: 0.8124\n",
      "Epoch 353/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5066 - accuracy: 0.8164\n",
      "Epoch 354/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5182 - accuracy: 0.8149\n",
      "Epoch 355/1000\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.5229 - accuracy: 0.8051\n",
      "Epoch 356/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4810 - accuracy: 0.8232\n",
      "Epoch 357/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.8178\n",
      "Epoch 358/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5157 - accuracy: 0.8083\n",
      "Epoch 359/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4991 - accuracy: 0.8208\n",
      "Epoch 360/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5072 - accuracy: 0.8131\n",
      "Epoch 361/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5017 - accuracy: 0.8192\n",
      "Epoch 362/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4997 - accuracy: 0.8141\n",
      "Epoch 363/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5112 - accuracy: 0.8106\n",
      "Epoch 364/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5015 - accuracy: 0.8158\n",
      "Epoch 365/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5216 - accuracy: 0.8113\n",
      "Epoch 366/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4970 - accuracy: 0.8232\n",
      "Epoch 367/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5083 - accuracy: 0.8109\n",
      "Epoch 368/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5344 - accuracy: 0.8059\n",
      "Epoch 369/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5010 - accuracy: 0.8183\n",
      "Epoch 370/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5049 - accuracy: 0.8183\n",
      "Epoch 371/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5079 - accuracy: 0.8133\n",
      "Epoch 372/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5086 - accuracy: 0.8173\n",
      "Epoch 373/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4807 - accuracy: 0.8304\n",
      "Epoch 374/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5020 - accuracy: 0.8209\n",
      "Epoch 375/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4873 - accuracy: 0.8231\n",
      "Epoch 376/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5098 - accuracy: 0.8087\n",
      "Epoch 377/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5043 - accuracy: 0.8175\n",
      "Epoch 378/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5065 - accuracy: 0.8123\n",
      "Epoch 379/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5099 - accuracy: 0.8091\n",
      "Epoch 380/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5061 - accuracy: 0.8146\n",
      "Epoch 381/1000\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.5173 - accuracy: 0.8041\n",
      "Epoch 382/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5098 - accuracy: 0.8138\n",
      "Epoch 383/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4901 - accuracy: 0.8203\n",
      "Epoch 384/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5069 - accuracy: 0.8196\n",
      "Epoch 385/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4888 - accuracy: 0.8238\n",
      "Epoch 386/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5216 - accuracy: 0.8110\n",
      "Epoch 387/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4900 - accuracy: 0.8241\n",
      "Epoch 388/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5208 - accuracy: 0.8067\n",
      "Epoch 389/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4934 - accuracy: 0.8180\n",
      "Epoch 390/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5063 - accuracy: 0.8155\n",
      "Epoch 391/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4992 - accuracy: 0.8212\n",
      "Epoch 392/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5199 - accuracy: 0.8022\n",
      "Epoch 393/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5089 - accuracy: 0.8135\n",
      "Epoch 394/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.8189\n",
      "Epoch 395/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5033 - accuracy: 0.8083\n",
      "Epoch 396/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4997 - accuracy: 0.8082\n",
      "Epoch 397/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4910 - accuracy: 0.8207\n",
      "Epoch 398/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4823 - accuracy: 0.8274\n",
      "Epoch 399/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5105 - accuracy: 0.8105\n",
      "Epoch 400/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4974 - accuracy: 0.8152\n",
      "Epoch 401/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5117 - accuracy: 0.8146\n",
      "Epoch 402/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4921 - accuracy: 0.8211\n",
      "Epoch 403/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5237 - accuracy: 0.8009\n",
      "Epoch 404/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5179 - accuracy: 0.8112\n",
      "Epoch 405/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5037 - accuracy: 0.8238\n",
      "Epoch 406/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5157 - accuracy: 0.8066\n",
      "Epoch 407/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5307 - accuracy: 0.8009\n",
      "Epoch 408/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5113 - accuracy: 0.8153\n",
      "Epoch 409/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4926 - accuracy: 0.8214\n",
      "Epoch 410/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5171 - accuracy: 0.8133\n",
      "Epoch 411/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4892 - accuracy: 0.8175\n",
      "Epoch 412/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5204 - accuracy: 0.8078\n",
      "Epoch 413/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5187 - accuracy: 0.8101\n",
      "Epoch 414/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5128 - accuracy: 0.8083\n",
      "Epoch 415/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4998 - accuracy: 0.8222\n",
      "Epoch 416/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4941 - accuracy: 0.8186\n",
      "Epoch 417/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5201 - accuracy: 0.8102\n",
      "Epoch 418/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5351 - accuracy: 0.7971\n",
      "Epoch 419/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4879 - accuracy: 0.8270\n",
      "Epoch 420/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5082 - accuracy: 0.8172\n",
      "Epoch 421/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5021 - accuracy: 0.8150\n",
      "Epoch 422/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4974 - accuracy: 0.8168\n",
      "Epoch 423/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5089 - accuracy: 0.8136\n",
      "Epoch 424/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4996 - accuracy: 0.8158\n",
      "Epoch 425/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5014 - accuracy: 0.8159\n",
      "Epoch 426/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4860 - accuracy: 0.8300\n",
      "Epoch 427/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5051 - accuracy: 0.8200\n",
      "Epoch 428/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5019 - accuracy: 0.8175\n",
      "Epoch 429/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.8103\n",
      "Epoch 430/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5129 - accuracy: 0.8126\n",
      "Epoch 431/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4928 - accuracy: 0.8246\n",
      "Epoch 432/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5001 - accuracy: 0.8169\n",
      "Epoch 433/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4877 - accuracy: 0.8278\n",
      "Epoch 434/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4749 - accuracy: 0.8324\n",
      "Epoch 435/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5013 - accuracy: 0.8131\n",
      "Epoch 436/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4939 - accuracy: 0.8233\n",
      "Epoch 437/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5119 - accuracy: 0.8127\n",
      "Epoch 438/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4915 - accuracy: 0.8200\n",
      "Epoch 439/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5137 - accuracy: 0.8205\n",
      "Epoch 440/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4935 - accuracy: 0.8179\n",
      "Epoch 441/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5114 - accuracy: 0.8126\n",
      "Epoch 442/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4868 - accuracy: 0.8213\n",
      "Epoch 443/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5094 - accuracy: 0.8056\n",
      "Epoch 444/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4696 - accuracy: 0.8278\n",
      "Epoch 445/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4890 - accuracy: 0.8237\n",
      "Epoch 446/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5055 - accuracy: 0.8156\n",
      "Epoch 447/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5118 - accuracy: 0.8077\n",
      "Epoch 448/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5202 - accuracy: 0.8069\n",
      "Epoch 449/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5004 - accuracy: 0.8132\n",
      "Epoch 450/1000\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.5171 - accuracy: 0.8145\n",
      "Epoch 451/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5008 - accuracy: 0.8249\n",
      "Epoch 452/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4937 - accuracy: 0.8246\n",
      "Epoch 453/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5115 - accuracy: 0.8097\n",
      "Epoch 454/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5114 - accuracy: 0.8095\n",
      "Epoch 455/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5245 - accuracy: 0.8060\n",
      "Epoch 456/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4979 - accuracy: 0.8221\n",
      "Epoch 457/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5105 - accuracy: 0.8098\n",
      "Epoch 458/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4760 - accuracy: 0.8256\n",
      "Epoch 459/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4845 - accuracy: 0.8219\n",
      "Epoch 460/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4914 - accuracy: 0.8204\n",
      "Epoch 461/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4734 - accuracy: 0.8253\n",
      "Epoch 462/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4968 - accuracy: 0.8185\n",
      "Epoch 463/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5226 - accuracy: 0.8045\n",
      "Epoch 464/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5038 - accuracy: 0.8125\n",
      "Epoch 465/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5001 - accuracy: 0.8226\n",
      "Epoch 466/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5199 - accuracy: 0.8091\n",
      "Epoch 467/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4989 - accuracy: 0.8152\n",
      "Epoch 468/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4989 - accuracy: 0.8110\n",
      "Epoch 469/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5015 - accuracy: 0.8167\n",
      "Epoch 470/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4878 - accuracy: 0.8264\n",
      "Epoch 471/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5003 - accuracy: 0.8196\n",
      "Epoch 472/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4939 - accuracy: 0.8176\n",
      "Epoch 473/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5100 - accuracy: 0.8125\n",
      "Epoch 474/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5117 - accuracy: 0.8165\n",
      "Epoch 475/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4892 - accuracy: 0.8235\n",
      "Epoch 476/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5083 - accuracy: 0.8092\n",
      "Epoch 477/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5214 - accuracy: 0.8034\n",
      "Epoch 478/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5036 - accuracy: 0.8123\n",
      "Epoch 479/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4966 - accuracy: 0.8166\n",
      "Epoch 480/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4810 - accuracy: 0.8281\n",
      "Epoch 481/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4915 - accuracy: 0.8131\n",
      "Epoch 482/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5149 - accuracy: 0.8123\n",
      "Epoch 483/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5119 - accuracy: 0.8127\n",
      "Epoch 484/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5045 - accuracy: 0.8108\n",
      "Epoch 485/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4966 - accuracy: 0.8220\n",
      "Epoch 486/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5080 - accuracy: 0.8071\n",
      "Epoch 487/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4900 - accuracy: 0.8223\n",
      "Epoch 488/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.4912 - accuracy: 0.8209\n",
      "Epoch 489/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4970 - accuracy: 0.8143\n",
      "Epoch 490/1000\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.4783 - accuracy: 0.8254\n",
      "Epoch 491/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4986 - accuracy: 0.8210\n",
      "Epoch 492/1000\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.5046 - accuracy: 0.8196\n",
      "Epoch 493/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5237 - accuracy: 0.8070\n",
      "Epoch 494/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4892 - accuracy: 0.8272\n",
      "Epoch 495/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5095 - accuracy: 0.8102\n",
      "Epoch 496/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5092 - accuracy: 0.8147\n",
      "Epoch 497/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4934 - accuracy: 0.8209\n",
      "Epoch 498/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.8196\n",
      "Epoch 499/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4949 - accuracy: 0.8188\n",
      "Epoch 500/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4957 - accuracy: 0.8209\n",
      "Epoch 501/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5089 - accuracy: 0.8110\n",
      "Epoch 502/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5196 - accuracy: 0.8082\n",
      "Epoch 503/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4990 - accuracy: 0.8146\n",
      "Epoch 504/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5073 - accuracy: 0.8099\n",
      "Epoch 505/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5110 - accuracy: 0.8103\n",
      "Epoch 506/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5280 - accuracy: 0.8074\n",
      "Epoch 507/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4904 - accuracy: 0.8145\n",
      "Epoch 508/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4955 - accuracy: 0.8227\n",
      "Epoch 509/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4910 - accuracy: 0.8220\n",
      "Epoch 510/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4945 - accuracy: 0.8192\n",
      "Epoch 511/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4940 - accuracy: 0.8200\n",
      "Epoch 512/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5189 - accuracy: 0.8061\n",
      "Epoch 513/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4975 - accuracy: 0.8184\n",
      "Epoch 514/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5120 - accuracy: 0.8034\n",
      "Epoch 515/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5100 - accuracy: 0.8104\n",
      "Epoch 516/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5017 - accuracy: 0.8136\n",
      "Epoch 517/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4766 - accuracy: 0.8304\n",
      "Epoch 518/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5096 - accuracy: 0.8104\n",
      "Epoch 519/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5089 - accuracy: 0.8156\n",
      "Epoch 520/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5038 - accuracy: 0.8217\n",
      "Epoch 521/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5163 - accuracy: 0.8064\n",
      "Epoch 522/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4652 - accuracy: 0.8305\n",
      "Epoch 523/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4931 - accuracy: 0.8196\n",
      "Epoch 524/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4934 - accuracy: 0.8212\n",
      "Epoch 525/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4908 - accuracy: 0.8218\n",
      "Epoch 526/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4777 - accuracy: 0.8301\n",
      "Epoch 527/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4890 - accuracy: 0.8195\n",
      "Epoch 528/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4942 - accuracy: 0.8134\n",
      "Epoch 529/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5037 - accuracy: 0.8134\n",
      "Epoch 530/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5271 - accuracy: 0.7966\n",
      "Epoch 531/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5078 - accuracy: 0.8166\n",
      "Epoch 532/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5123 - accuracy: 0.8084\n",
      "Epoch 533/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5160 - accuracy: 0.8062\n",
      "Epoch 534/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5033 - accuracy: 0.8141\n",
      "Epoch 535/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5086 - accuracy: 0.8166\n",
      "Epoch 536/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.8213\n",
      "Epoch 537/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4891 - accuracy: 0.8260\n",
      "Epoch 538/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.4919 - accuracy: 0.8142\n",
      "Epoch 539/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5207 - accuracy: 0.8012\n",
      "Epoch 540/1000\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.5022 - accuracy: 0.8124\n",
      "Epoch 541/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4887 - accuracy: 0.8196\n",
      "Epoch 542/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4827 - accuracy: 0.8241\n",
      "Epoch 543/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4965 - accuracy: 0.8180\n",
      "Epoch 544/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5085 - accuracy: 0.8155\n",
      "Epoch 545/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4975 - accuracy: 0.8199\n",
      "Epoch 546/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4998 - accuracy: 0.8194\n",
      "Epoch 547/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4871 - accuracy: 0.8238\n",
      "Epoch 548/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4869 - accuracy: 0.8187\n",
      "Epoch 549/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4763 - accuracy: 0.8241\n",
      "Epoch 550/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4827 - accuracy: 0.8242\n",
      "Epoch 551/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4965 - accuracy: 0.8168\n",
      "Epoch 552/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5020 - accuracy: 0.8192\n",
      "Epoch 553/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4947 - accuracy: 0.8187\n",
      "Epoch 554/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5121 - accuracy: 0.8130\n",
      "Epoch 555/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.8271\n",
      "Epoch 556/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5103 - accuracy: 0.8202\n",
      "Epoch 557/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.8263\n",
      "Epoch 558/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5031 - accuracy: 0.8165\n",
      "Epoch 559/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4905 - accuracy: 0.8174\n",
      "Epoch 560/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4833 - accuracy: 0.8133\n",
      "Epoch 561/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5194 - accuracy: 0.8066\n",
      "Epoch 562/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.8235\n",
      "Epoch 563/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5083 - accuracy: 0.8126\n",
      "Epoch 564/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4717 - accuracy: 0.8319\n",
      "Epoch 565/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4903 - accuracy: 0.8167\n",
      "Epoch 566/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4701 - accuracy: 0.8282\n",
      "Epoch 567/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4905 - accuracy: 0.8231\n",
      "Epoch 568/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4951 - accuracy: 0.8231\n",
      "Epoch 569/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5175 - accuracy: 0.8071\n",
      "Epoch 570/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.8235\n",
      "Epoch 571/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5161 - accuracy: 0.8123\n",
      "Epoch 572/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4874 - accuracy: 0.8202\n",
      "Epoch 573/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5029 - accuracy: 0.8181\n",
      "Epoch 574/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4853 - accuracy: 0.8134\n",
      "Epoch 575/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4921 - accuracy: 0.8205\n",
      "Epoch 576/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4835 - accuracy: 0.8245\n",
      "Epoch 577/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5126 - accuracy: 0.8120\n",
      "Epoch 578/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.8181\n",
      "Epoch 579/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5005 - accuracy: 0.8182\n",
      "Epoch 580/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4715 - accuracy: 0.8297\n",
      "Epoch 581/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5100 - accuracy: 0.8154\n",
      "Epoch 582/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4899 - accuracy: 0.8275\n",
      "Epoch 583/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4944 - accuracy: 0.8140\n",
      "Epoch 584/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4870 - accuracy: 0.8185\n",
      "Epoch 585/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4982 - accuracy: 0.8153\n",
      "Epoch 586/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5101 - accuracy: 0.8091\n",
      "Epoch 587/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4672 - accuracy: 0.8272\n",
      "Epoch 588/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5061 - accuracy: 0.8142\n",
      "Epoch 589/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4922 - accuracy: 0.8245\n",
      "Epoch 590/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5088 - accuracy: 0.8164\n",
      "Epoch 591/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5002 - accuracy: 0.8180\n",
      "Epoch 592/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4957 - accuracy: 0.8125\n",
      "Epoch 593/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4943 - accuracy: 0.8183\n",
      "Epoch 594/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5029 - accuracy: 0.8107\n",
      "Epoch 595/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5009 - accuracy: 0.8110\n",
      "Epoch 596/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4826 - accuracy: 0.8289\n",
      "Epoch 597/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4932 - accuracy: 0.8196\n",
      "Epoch 598/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4943 - accuracy: 0.8216\n",
      "Epoch 599/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4764 - accuracy: 0.8276\n",
      "Epoch 600/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5025 - accuracy: 0.8084\n",
      "Epoch 601/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4963 - accuracy: 0.8137\n",
      "Epoch 602/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4891 - accuracy: 0.8216\n",
      "Epoch 603/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5130 - accuracy: 0.8108\n",
      "Epoch 604/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4926 - accuracy: 0.8161\n",
      "Epoch 605/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.4984 - accuracy: 0.8245\n",
      "Epoch 606/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4975 - accuracy: 0.8124\n",
      "Epoch 607/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4650 - accuracy: 0.8292\n",
      "Epoch 608/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4996 - accuracy: 0.8158\n",
      "Epoch 609/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4903 - accuracy: 0.8201\n",
      "Epoch 610/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4723 - accuracy: 0.8268\n",
      "Epoch 611/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4820 - accuracy: 0.8264\n",
      "Epoch 612/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4908 - accuracy: 0.8193\n",
      "Epoch 613/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4791 - accuracy: 0.8255\n",
      "Epoch 614/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4893 - accuracy: 0.8199\n",
      "Epoch 615/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4889 - accuracy: 0.8178\n",
      "Epoch 616/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4992 - accuracy: 0.8206\n",
      "Epoch 617/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5150 - accuracy: 0.8123\n",
      "Epoch 618/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.8169\n",
      "Epoch 619/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4790 - accuracy: 0.8252\n",
      "Epoch 620/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4947 - accuracy: 0.8131\n",
      "Epoch 621/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4836 - accuracy: 0.8286\n",
      "Epoch 622/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5126 - accuracy: 0.8076\n",
      "Epoch 623/1000\n",
      "348/348 [==============================] - ETA: 0s - loss: 0.4863 - accuracy: 0.82 - 0s 1ms/step - loss: 0.4869 - accuracy: 0.8210\n",
      "Epoch 624/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5182 - accuracy: 0.8158\n",
      "Epoch 625/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4849 - accuracy: 0.8186\n",
      "Epoch 626/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4851 - accuracy: 0.8232\n",
      "Epoch 627/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4747 - accuracy: 0.8304\n",
      "Epoch 628/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5107 - accuracy: 0.8095\n",
      "Epoch 629/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4713 - accuracy: 0.8290\n",
      "Epoch 630/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5118 - accuracy: 0.8104\n",
      "Epoch 631/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5402 - accuracy: 0.8014\n",
      "Epoch 632/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5034 - accuracy: 0.8173\n",
      "Epoch 633/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.8152\n",
      "Epoch 634/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4979 - accuracy: 0.8127\n",
      "Epoch 635/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5001 - accuracy: 0.8174\n",
      "Epoch 636/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4927 - accuracy: 0.8180\n",
      "Epoch 637/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5195 - accuracy: 0.8089\n",
      "Epoch 638/1000\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.4734 - accuracy: 0.8192\n",
      "Epoch 639/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.4944 - accuracy: 0.8151\n",
      "Epoch 640/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4757 - accuracy: 0.8291\n",
      "Epoch 641/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5039 - accuracy: 0.8163\n",
      "Epoch 642/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4674 - accuracy: 0.8303\n",
      "Epoch 643/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.8156\n",
      "Epoch 644/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.8182\n",
      "Epoch 645/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.8260\n",
      "Epoch 646/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5037 - accuracy: 0.8068\n",
      "Epoch 647/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4938 - accuracy: 0.8192\n",
      "Epoch 648/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5033 - accuracy: 0.8128\n",
      "Epoch 649/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5012 - accuracy: 0.8145\n",
      "Epoch 650/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4988 - accuracy: 0.8150\n",
      "Epoch 651/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4972 - accuracy: 0.8190\n",
      "Epoch 652/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5143 - accuracy: 0.8128\n",
      "Epoch 653/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4711 - accuracy: 0.8249\n",
      "Epoch 654/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4672 - accuracy: 0.8322\n",
      "Epoch 655/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4678 - accuracy: 0.8300\n",
      "Epoch 656/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4879 - accuracy: 0.8201\n",
      "Epoch 657/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4915 - accuracy: 0.8189\n",
      "Epoch 658/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4762 - accuracy: 0.8201\n",
      "Epoch 659/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5011 - accuracy: 0.8126\n",
      "Epoch 660/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4756 - accuracy: 0.8315\n",
      "Epoch 661/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4890 - accuracy: 0.8223\n",
      "Epoch 662/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4972 - accuracy: 0.8167\n",
      "Epoch 663/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5012 - accuracy: 0.8155\n",
      "Epoch 664/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4976 - accuracy: 0.8134\n",
      "Epoch 665/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5158 - accuracy: 0.8089\n",
      "Epoch 666/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4891 - accuracy: 0.8208\n",
      "Epoch 667/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4988 - accuracy: 0.8129\n",
      "Epoch 668/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4656 - accuracy: 0.8354\n",
      "Epoch 669/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4862 - accuracy: 0.8292\n",
      "Epoch 670/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5041 - accuracy: 0.8079\n",
      "Epoch 671/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4721 - accuracy: 0.8245\n",
      "Epoch 672/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4984 - accuracy: 0.8233\n",
      "Epoch 673/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4844 - accuracy: 0.8250\n",
      "Epoch 674/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5064 - accuracy: 0.8118\n",
      "Epoch 675/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5130 - accuracy: 0.8119\n",
      "Epoch 676/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4842 - accuracy: 0.8242\n",
      "Epoch 677/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4924 - accuracy: 0.8209\n",
      "Epoch 678/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4922 - accuracy: 0.8151\n",
      "Epoch 679/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4865 - accuracy: 0.8243\n",
      "Epoch 680/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5010 - accuracy: 0.8206\n",
      "Epoch 681/1000\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.4870 - accuracy: 0.8195\n",
      "Epoch 682/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4881 - accuracy: 0.8224\n",
      "Epoch 683/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5177 - accuracy: 0.8158\n",
      "Epoch 684/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4887 - accuracy: 0.8169\n",
      "Epoch 685/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4864 - accuracy: 0.8224\n",
      "Epoch 686/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4987 - accuracy: 0.8197\n",
      "Epoch 687/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4901 - accuracy: 0.8179\n",
      "Epoch 688/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4597 - accuracy: 0.8371\n",
      "Epoch 689/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4926 - accuracy: 0.8228\n",
      "Epoch 690/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4860 - accuracy: 0.8203\n",
      "Epoch 691/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4715 - accuracy: 0.8285\n",
      "Epoch 692/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4939 - accuracy: 0.8225\n",
      "Epoch 693/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5085 - accuracy: 0.8122\n",
      "Epoch 694/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5120 - accuracy: 0.8112\n",
      "Epoch 695/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4841 - accuracy: 0.8234\n",
      "Epoch 696/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4819 - accuracy: 0.8243\n",
      "Epoch 697/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5042 - accuracy: 0.8154\n",
      "Epoch 698/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5029 - accuracy: 0.8218\n",
      "Epoch 699/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4928 - accuracy: 0.8239\n",
      "Epoch 700/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4977 - accuracy: 0.8206: 0s - loss: 0.5065 - ac\n",
      "Epoch 701/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4898 - accuracy: 0.8169\n",
      "Epoch 702/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4962 - accuracy: 0.8176\n",
      "Epoch 703/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5181 - accuracy: 0.8053\n",
      "Epoch 704/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4933 - accuracy: 0.8131\n",
      "Epoch 705/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4817 - accuracy: 0.8279\n",
      "Epoch 706/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4916 - accuracy: 0.8176\n",
      "Epoch 707/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4758 - accuracy: 0.8216\n",
      "Epoch 708/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4763 - accuracy: 0.8323\n",
      "Epoch 709/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4807 - accuracy: 0.8217\n",
      "Epoch 710/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4891 - accuracy: 0.8190\n",
      "Epoch 711/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4825 - accuracy: 0.8192\n",
      "Epoch 712/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4969 - accuracy: 0.8117\n",
      "Epoch 713/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5105 - accuracy: 0.8146\n",
      "Epoch 714/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4756 - accuracy: 0.8239\n",
      "Epoch 715/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4969 - accuracy: 0.8152\n",
      "Epoch 716/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5009 - accuracy: 0.8206\n",
      "Epoch 717/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4794 - accuracy: 0.8298\n",
      "Epoch 718/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4835 - accuracy: 0.8280\n",
      "Epoch 719/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5086 - accuracy: 0.8147\n",
      "Epoch 720/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5070 - accuracy: 0.8168\n",
      "Epoch 721/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4848 - accuracy: 0.8186\n",
      "Epoch 722/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5018 - accuracy: 0.8180\n",
      "Epoch 723/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5022 - accuracy: 0.8181\n",
      "Epoch 724/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4976 - accuracy: 0.8241\n",
      "Epoch 725/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4820 - accuracy: 0.8182\n",
      "Epoch 726/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4984 - accuracy: 0.8212\n",
      "Epoch 727/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4894 - accuracy: 0.8136\n",
      "Epoch 728/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4840 - accuracy: 0.8249\n",
      "Epoch 729/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4813 - accuracy: 0.8177\n",
      "Epoch 730/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4858 - accuracy: 0.8175\n",
      "Epoch 731/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4908 - accuracy: 0.8232\n",
      "Epoch 732/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4876 - accuracy: 0.8208\n",
      "Epoch 733/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4813 - accuracy: 0.8231\n",
      "Epoch 734/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5141 - accuracy: 0.8103\n",
      "Epoch 735/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4872 - accuracy: 0.8198\n",
      "Epoch 736/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4920 - accuracy: 0.8139\n",
      "Epoch 737/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5022 - accuracy: 0.8175\n",
      "Epoch 738/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4937 - accuracy: 0.8220\n",
      "Epoch 739/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5058 - accuracy: 0.8229\n",
      "Epoch 740/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4967 - accuracy: 0.8249\n",
      "Epoch 741/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5080 - accuracy: 0.8107\n",
      "Epoch 742/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4673 - accuracy: 0.8245\n",
      "Epoch 743/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4914 - accuracy: 0.8188\n",
      "Epoch 744/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4852 - accuracy: 0.8191\n",
      "Epoch 745/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4733 - accuracy: 0.8268\n",
      "Epoch 746/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5148 - accuracy: 0.8099\n",
      "Epoch 747/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4941 - accuracy: 0.8190\n",
      "Epoch 748/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4673 - accuracy: 0.8385\n",
      "Epoch 749/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4908 - accuracy: 0.8208\n",
      "Epoch 750/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5012 - accuracy: 0.8133\n",
      "Epoch 751/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4950 - accuracy: 0.8207\n",
      "Epoch 752/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5187 - accuracy: 0.8060\n",
      "Epoch 753/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4898 - accuracy: 0.8228\n",
      "Epoch 754/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4865 - accuracy: 0.8215\n",
      "Epoch 755/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5081 - accuracy: 0.8106\n",
      "Epoch 756/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4696 - accuracy: 0.8222\n",
      "Epoch 757/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.8081\n",
      "Epoch 758/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4972 - accuracy: 0.8212\n",
      "Epoch 759/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4926 - accuracy: 0.8199\n",
      "Epoch 760/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4774 - accuracy: 0.8253\n",
      "Epoch 761/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4757 - accuracy: 0.8266\n",
      "Epoch 762/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4951 - accuracy: 0.8206\n",
      "Epoch 763/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5028 - accuracy: 0.8193\n",
      "Epoch 764/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4991 - accuracy: 0.8133\n",
      "Epoch 765/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4792 - accuracy: 0.8191\n",
      "Epoch 766/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4751 - accuracy: 0.8283\n",
      "Epoch 767/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5008 - accuracy: 0.8108\n",
      "Epoch 768/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4949 - accuracy: 0.8147\n",
      "Epoch 769/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4853 - accuracy: 0.8226\n",
      "Epoch 770/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4857 - accuracy: 0.8259\n",
      "Epoch 771/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5039 - accuracy: 0.8206\n",
      "Epoch 772/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4932 - accuracy: 0.8158\n",
      "Epoch 773/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5022 - accuracy: 0.8173\n",
      "Epoch 774/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4912 - accuracy: 0.8228\n",
      "Epoch 775/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5109 - accuracy: 0.8070\n",
      "Epoch 776/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4900 - accuracy: 0.8198\n",
      "Epoch 777/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4787 - accuracy: 0.8250\n",
      "Epoch 778/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4917 - accuracy: 0.8218\n",
      "Epoch 779/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4789 - accuracy: 0.8190\n",
      "Epoch 780/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4879 - accuracy: 0.8192\n",
      "Epoch 781/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4815 - accuracy: 0.8267\n",
      "Epoch 782/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4979 - accuracy: 0.8202\n",
      "Epoch 783/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4936 - accuracy: 0.8200\n",
      "Epoch 784/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.4943 - accuracy: 0.8189\n",
      "Epoch 785/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4808 - accuracy: 0.8237\n",
      "Epoch 786/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5171 - accuracy: 0.8027\n",
      "Epoch 787/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.8117\n",
      "Epoch 788/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4864 - accuracy: 0.8254\n",
      "Epoch 789/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4981 - accuracy: 0.8139\n",
      "Epoch 790/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4768 - accuracy: 0.8260\n",
      "Epoch 791/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5039 - accuracy: 0.8127\n",
      "Epoch 792/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4951 - accuracy: 0.8213\n",
      "Epoch 793/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4887 - accuracy: 0.8211\n",
      "Epoch 794/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4929 - accuracy: 0.8173\n",
      "Epoch 795/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5108 - accuracy: 0.8129\n",
      "Epoch 796/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4865 - accuracy: 0.8278\n",
      "Epoch 797/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4996 - accuracy: 0.8202\n",
      "Epoch 798/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5049 - accuracy: 0.8069\n",
      "Epoch 799/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4955 - accuracy: 0.8126\n",
      "Epoch 800/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5205 - accuracy: 0.8057\n",
      "Epoch 801/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5068 - accuracy: 0.8174\n",
      "Epoch 802/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4790 - accuracy: 0.8226\n",
      "Epoch 803/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4858 - accuracy: 0.8153\n",
      "Epoch 804/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5061 - accuracy: 0.8123\n",
      "Epoch 805/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4845 - accuracy: 0.8139\n",
      "Epoch 806/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4875 - accuracy: 0.8223\n",
      "Epoch 807/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4785 - accuracy: 0.8241\n",
      "Epoch 808/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5045 - accuracy: 0.8091\n",
      "Epoch 809/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5073 - accuracy: 0.8152\n",
      "Epoch 810/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4823 - accuracy: 0.8279\n",
      "Epoch 811/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5003 - accuracy: 0.8156\n",
      "Epoch 812/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4728 - accuracy: 0.8282\n",
      "Epoch 813/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4985 - accuracy: 0.8072\n",
      "Epoch 814/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4756 - accuracy: 0.8235\n",
      "Epoch 815/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4961 - accuracy: 0.8160\n",
      "Epoch 816/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4848 - accuracy: 0.8229\n",
      "Epoch 817/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4705 - accuracy: 0.8271\n",
      "Epoch 818/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4937 - accuracy: 0.8118\n",
      "Epoch 819/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4966 - accuracy: 0.8124\n",
      "Epoch 820/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.8228\n",
      "Epoch 821/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4903 - accuracy: 0.8166\n",
      "Epoch 822/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4934 - accuracy: 0.8215\n",
      "Epoch 823/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5011 - accuracy: 0.8166\n",
      "Epoch 824/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4952 - accuracy: 0.8120\n",
      "Epoch 825/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.8225: 0s - loss: 0.4403 - \n",
      "Epoch 826/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4872 - accuracy: 0.8145\n",
      "Epoch 827/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4782 - accuracy: 0.8273\n",
      "Epoch 828/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5071 - accuracy: 0.8106\n",
      "Epoch 829/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4711 - accuracy: 0.8266\n",
      "Epoch 830/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4853 - accuracy: 0.8254\n",
      "Epoch 831/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5139 - accuracy: 0.8051\n",
      "Epoch 832/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4710 - accuracy: 0.8343\n",
      "Epoch 833/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4808 - accuracy: 0.8304\n",
      "Epoch 834/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4790 - accuracy: 0.8231\n",
      "Epoch 835/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5047 - accuracy: 0.8159\n",
      "Epoch 836/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.8344\n",
      "Epoch 837/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4683 - accuracy: 0.8292\n",
      "Epoch 838/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4944 - accuracy: 0.8131\n",
      "Epoch 839/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4688 - accuracy: 0.8222\n",
      "Epoch 840/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4921 - accuracy: 0.8207\n",
      "Epoch 841/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4702 - accuracy: 0.8255\n",
      "Epoch 842/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4944 - accuracy: 0.8122\n",
      "Epoch 843/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4950 - accuracy: 0.8113\n",
      "Epoch 844/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5102 - accuracy: 0.8027\n",
      "Epoch 845/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5055 - accuracy: 0.8100\n",
      "Epoch 846/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4903 - accuracy: 0.8171\n",
      "Epoch 847/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4952 - accuracy: 0.8186\n",
      "Epoch 848/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4986 - accuracy: 0.8170\n",
      "Epoch 849/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4958 - accuracy: 0.8205\n",
      "Epoch 850/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4961 - accuracy: 0.8189\n",
      "Epoch 851/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4895 - accuracy: 0.8249\n",
      "Epoch 852/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.4824 - accuracy: 0.8339\n",
      "Epoch 853/1000\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.4997 - accuracy: 0.8119\n",
      "Epoch 854/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5096 - accuracy: 0.8059\n",
      "Epoch 855/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4639 - accuracy: 0.8252\n",
      "Epoch 856/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4960 - accuracy: 0.8202\n",
      "Epoch 857/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4748 - accuracy: 0.8227\n",
      "Epoch 858/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4944 - accuracy: 0.8107\n",
      "Epoch 859/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4963 - accuracy: 0.8141\n",
      "Epoch 860/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4926 - accuracy: 0.8127\n",
      "Epoch 861/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4774 - accuracy: 0.8194\n",
      "Epoch 862/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4953 - accuracy: 0.8176\n",
      "Epoch 863/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4961 - accuracy: 0.8178\n",
      "Epoch 864/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4913 - accuracy: 0.8157\n",
      "Epoch 865/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4925 - accuracy: 0.8158\n",
      "Epoch 866/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.8207\n",
      "Epoch 867/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4946 - accuracy: 0.8108\n",
      "Epoch 868/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5044 - accuracy: 0.8120\n",
      "Epoch 869/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4909 - accuracy: 0.8170\n",
      "Epoch 870/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5025 - accuracy: 0.8175\n",
      "Epoch 871/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.8205\n",
      "Epoch 872/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4985 - accuracy: 0.8160\n",
      "Epoch 873/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4955 - accuracy: 0.8193\n",
      "Epoch 874/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4977 - accuracy: 0.8177\n",
      "Epoch 875/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4931 - accuracy: 0.8209\n",
      "Epoch 876/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4778 - accuracy: 0.8249\n",
      "Epoch 877/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4921 - accuracy: 0.8229\n",
      "Epoch 878/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4796 - accuracy: 0.8154\n",
      "Epoch 879/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4695 - accuracy: 0.8266\n",
      "Epoch 880/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5003 - accuracy: 0.8110\n",
      "Epoch 881/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4858 - accuracy: 0.8194\n",
      "Epoch 882/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4944 - accuracy: 0.8146\n",
      "Epoch 883/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4834 - accuracy: 0.8262\n",
      "Epoch 884/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4859 - accuracy: 0.8230\n",
      "Epoch 885/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4690 - accuracy: 0.8245\n",
      "Epoch 886/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4772 - accuracy: 0.8210\n",
      "Epoch 887/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5094 - accuracy: 0.8188\n",
      "Epoch 888/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4870 - accuracy: 0.8175\n",
      "Epoch 889/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4689 - accuracy: 0.8324\n",
      "Epoch 890/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4943 - accuracy: 0.8199\n",
      "Epoch 891/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4951 - accuracy: 0.8250\n",
      "Epoch 892/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4926 - accuracy: 0.8184\n",
      "Epoch 893/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4692 - accuracy: 0.8295\n",
      "Epoch 894/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4793 - accuracy: 0.8174\n",
      "Epoch 895/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4875 - accuracy: 0.8177\n",
      "Epoch 896/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4848 - accuracy: 0.8188\n",
      "Epoch 897/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4946 - accuracy: 0.8166\n",
      "Epoch 898/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4793 - accuracy: 0.8309\n",
      "Epoch 899/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.8244\n",
      "Epoch 900/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4703 - accuracy: 0.8229\n",
      "Epoch 901/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.5098 - accuracy: 0.8042\n",
      "Epoch 902/1000\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.4924 - accuracy: 0.8154\n",
      "Epoch 903/1000\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.4815 - accuracy: 0.8269\n",
      "Epoch 904/1000\n",
      "348/348 [==============================] - 1s 1ms/step - loss: 0.5114 - accuracy: 0.8112\n",
      "Epoch 905/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4723 - accuracy: 0.8251\n",
      "Epoch 906/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4859 - accuracy: 0.8207\n",
      "Epoch 907/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4859 - accuracy: 0.8274\n",
      "Epoch 908/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5101 - accuracy: 0.8135\n",
      "Epoch 909/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5047 - accuracy: 0.8124\n",
      "Epoch 910/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4935 - accuracy: 0.8133\n",
      "Epoch 911/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4859 - accuracy: 0.8195\n",
      "Epoch 912/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4768 - accuracy: 0.8264\n",
      "Epoch 913/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4950 - accuracy: 0.8174\n",
      "Epoch 914/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5025 - accuracy: 0.8148\n",
      "Epoch 915/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4731 - accuracy: 0.8259\n",
      "Epoch 916/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4791 - accuracy: 0.8206\n",
      "Epoch 917/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5058 - accuracy: 0.8070\n",
      "Epoch 918/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4682 - accuracy: 0.8325\n",
      "Epoch 919/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4894 - accuracy: 0.8260\n",
      "Epoch 920/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4639 - accuracy: 0.8270\n",
      "Epoch 921/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5188 - accuracy: 0.8039\n",
      "Epoch 922/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4869 - accuracy: 0.8212\n",
      "Epoch 923/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5001 - accuracy: 0.8147\n",
      "Epoch 924/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4851 - accuracy: 0.8197\n",
      "Epoch 925/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4936 - accuracy: 0.8191\n",
      "Epoch 926/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4701 - accuracy: 0.8311\n",
      "Epoch 927/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5109 - accuracy: 0.8086\n",
      "Epoch 928/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4841 - accuracy: 0.8281\n",
      "Epoch 929/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4845 - accuracy: 0.8226\n",
      "Epoch 930/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4904 - accuracy: 0.8139\n",
      "Epoch 931/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4737 - accuracy: 0.8307\n",
      "Epoch 932/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4963 - accuracy: 0.8129\n",
      "Epoch 933/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4694 - accuracy: 0.8265\n",
      "Epoch 934/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4776 - accuracy: 0.8245\n",
      "Epoch 935/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4859 - accuracy: 0.8152\n",
      "Epoch 936/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.8199\n",
      "Epoch 937/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5031 - accuracy: 0.8266\n",
      "Epoch 938/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4891 - accuracy: 0.8270\n",
      "Epoch 939/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.8342\n",
      "Epoch 940/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4741 - accuracy: 0.8380\n",
      "Epoch 941/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4819 - accuracy: 0.8221\n",
      "Epoch 942/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4784 - accuracy: 0.8243\n",
      "Epoch 943/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4878 - accuracy: 0.8207\n",
      "Epoch 944/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.8253\n",
      "Epoch 945/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4822 - accuracy: 0.8208\n",
      "Epoch 946/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5097 - accuracy: 0.8173\n",
      "Epoch 947/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5048 - accuracy: 0.8108\n",
      "Epoch 948/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4992 - accuracy: 0.8223\n",
      "Epoch 949/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4920 - accuracy: 0.8126\n",
      "Epoch 950/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4967 - accuracy: 0.8153\n",
      "Epoch 951/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4729 - accuracy: 0.8278\n",
      "Epoch 952/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5127 - accuracy: 0.8100\n",
      "Epoch 953/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4819 - accuracy: 0.8224\n",
      "Epoch 954/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5012 - accuracy: 0.8127\n",
      "Epoch 955/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4862 - accuracy: 0.8216\n",
      "Epoch 956/1000\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.4982 - accuracy: 0.8153\n",
      "Epoch 957/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.8313\n",
      "Epoch 958/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4718 - accuracy: 0.8336\n",
      "Epoch 959/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4714 - accuracy: 0.8248\n",
      "Epoch 960/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5118 - accuracy: 0.8085\n",
      "Epoch 961/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4787 - accuracy: 0.8231\n",
      "Epoch 962/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4999 - accuracy: 0.8131\n",
      "Epoch 963/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.8407\n",
      "Epoch 964/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4768 - accuracy: 0.8267\n",
      "Epoch 965/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.8321\n",
      "Epoch 966/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4875 - accuracy: 0.8173\n",
      "Epoch 967/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4662 - accuracy: 0.8295\n",
      "Epoch 968/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4839 - accuracy: 0.8303\n",
      "Epoch 969/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4820 - accuracy: 0.8230\n",
      "Epoch 970/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4714 - accuracy: 0.8311\n",
      "Epoch 971/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4560 - accuracy: 0.8313: 0s - loss: 0.3989 - ac\n",
      "Epoch 972/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5015 - accuracy: 0.8015\n",
      "Epoch 973/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.8129\n",
      "Epoch 974/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4669 - accuracy: 0.8290\n",
      "Epoch 975/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4899 - accuracy: 0.8138\n",
      "Epoch 976/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4736 - accuracy: 0.8290\n",
      "Epoch 977/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4841 - accuracy: 0.8248\n",
      "Epoch 978/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4701 - accuracy: 0.8313\n",
      "Epoch 979/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4730 - accuracy: 0.8241\n",
      "Epoch 980/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4876 - accuracy: 0.8219\n",
      "Epoch 981/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4841 - accuracy: 0.8224\n",
      "Epoch 982/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5059 - accuracy: 0.8144\n",
      "Epoch 983/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4857 - accuracy: 0.8246\n",
      "Epoch 984/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.8180\n",
      "Epoch 985/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4904 - accuracy: 0.8299\n",
      "Epoch 986/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4839 - accuracy: 0.8180\n",
      "Epoch 987/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4748 - accuracy: 0.8277\n",
      "Epoch 988/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4894 - accuracy: 0.8277\n",
      "Epoch 989/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.5093 - accuracy: 0.8081\n",
      "Epoch 990/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4826 - accuracy: 0.8229\n",
      "Epoch 991/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4728 - accuracy: 0.8223\n",
      "Epoch 992/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4798 - accuracy: 0.8252\n",
      "Epoch 993/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4981 - accuracy: 0.8130\n",
      "Epoch 994/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4740 - accuracy: 0.8327\n",
      "Epoch 995/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4958 - accuracy: 0.8157\n",
      "Epoch 996/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4807 - accuracy: 0.8167\n",
      "Epoch 997/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4962 - accuracy: 0.8143\n",
      "Epoch 998/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4855 - accuracy: 0.8241\n",
      "Epoch 999/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4954 - accuracy: 0.8239\n",
      "Epoch 1000/1000\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.4884 - accuracy: 0.8226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d8747ce7f0>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "model.fit(X_train, y_train, batch_size=10, epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - 0s 1ms/step - loss: 0.4789 - accuracy: 0.8234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4789387881755829, 0.8233602046966553]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on test set\n",
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Root Mean Square Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error:  0.12168145\n",
      "root_mean_squared_error:  0.34882867\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print (\"mean_squared_error: \", mse)\n",
    "print (\"root_mean_squared_error: \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_test_class = np.argmax(y_test,axis=1)\n",
    "y_pred_class = np.argmax(y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.10      0.13       143\n",
      "           1       0.13      0.07      0.09       133\n",
      "           2       0.83      0.93      0.88      1214\n",
      "\n",
      "    accuracy                           0.77      1490\n",
      "   macro avg       0.39      0.36      0.37      1490\n",
      "weighted avg       0.71      0.77      0.73      1490\n",
      "\n",
      "[[  14    6  123]\n",
      " [  17    9  107]\n",
      " [  37   52 1125]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix, plot_confusion_matrix\n",
    "print(classification_report(y_test_class,y_pred_class))\n",
    "print(confusion_matrix(y_test_class,y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  14,    6,  123],\n",
       "       [  17,    9,  107],\n",
       "       [  37,   52, 1125]], dtype=int64)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test_class, y_pred_class)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ploting Confusion Matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.heatmap (cm, annot=True, cmap = 'Blues', fmt='g')\n",
    "plt.savefig('ANN - 3 Classes.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 9.18577075e-01,  7.99055398e-02, -1.37753159e-01,\n",
       "          1.19030428e+00, -1.24455893e+00, -1.30377322e-01,\n",
       "         -8.56670067e-02,  1.00998759e+00, -6.58023000e-01,\n",
       "          4.85747039e-01,  1.15179956e+00,  7.07815513e-02,\n",
       "         -3.61131907e-01,  8.71925354e-01,  7.79629529e-01,\n",
       "         -3.38309795e-01,  1.00169933e+00,  1.08522311e-01,\n",
       "          1.04077041e+00,  1.51123613e-01, -3.42059642e-01,\n",
       "          1.89471459e+00, -4.86760288e-01, -1.34093672e-01],\n",
       "        [-1.50456280e-01, -4.47983146e-01,  3.55061650e-01,\n",
       "         -3.91270369e-01,  4.83683079e-01, -3.13212752e-01,\n",
       "         -1.62146166e-02,  1.77296832e-01, -9.00670439e-02,\n",
       "         -3.58689427e-01, -4.26269114e-01,  1.88211814e-01,\n",
       "         -9.17512327e-02,  2.23932490e-02, -6.78160310e-01,\n",
       "         -4.65000212e-01,  2.37229958e-01,  2.56108105e-01,\n",
       "         -6.69449707e-03,  7.11254239e-01,  1.58154637e-01,\n",
       "         -6.44439995e-01,  3.35174382e-01, -1.92330539e-01],\n",
       "        [-7.62526631e-01,  9.49201226e-01, -7.45979369e-01,\n",
       "         -2.59231031e-01, -3.25786442e-01,  3.69939893e-01,\n",
       "          6.98106289e-01,  9.71820414e-01, -2.41815089e-03,\n",
       "          7.12591112e-01,  4.52023059e-01, -1.42236799e-01,\n",
       "         -4.93228823e-01,  4.62371886e-01,  8.87515247e-01,\n",
       "          8.63597989e-01, -2.57528722e-01, -9.89835337e-02,\n",
       "         -3.34698051e-01,  5.41837990e-01,  3.19345802e-01,\n",
       "         -9.63651061e-01,  8.02391171e-01,  4.28257495e-01],\n",
       "        [-3.46197695e-01, -1.96138620e-02, -6.84859753e-01,\n",
       "          1.50010979e+00, -3.01776558e-01,  4.12769318e-01,\n",
       "         -6.06157839e-01, -6.17112756e-01,  1.07262278e+00,\n",
       "         -3.82212788e-01, -6.13885581e-01, -9.23460126e-01,\n",
       "          2.46456087e-01, -4.75805670e-01,  7.18966007e-01,\n",
       "         -2.98261166e-01,  9.23821330e-01,  8.04530561e-01,\n",
       "         -4.45747197e-01, -1.63229966e+00, -4.30695385e-01,\n",
       "         -3.51405442e-02, -3.63783419e-01, -7.09164560e-01],\n",
       "        [ 1.41798472e+00, -4.80357707e-02,  2.84022421e-01,\n",
       "          8.51486623e-01,  1.21779764e+00,  3.07842046e-01,\n",
       "         -1.14228502e-01,  1.62500232e-01,  6.52020201e-02,\n",
       "          1.55717447e-01, -1.87857956e-01,  3.92490923e-01,\n",
       "         -6.94900334e-01,  1.67529836e-01,  1.76029837e+00,\n",
       "          7.06483781e-01,  6.77691400e-01,  1.85379893e-01,\n",
       "          3.68657410e-01, -1.39943257e-01, -8.85401309e-01,\n",
       "         -3.14409554e-01,  4.69957560e-01,  4.52459790e-02],\n",
       "        [ 1.91769619e-02,  1.94468871e-02,  1.05090415e+00,\n",
       "         -3.17544937e-01, -1.66982040e-02,  4.42302346e-01,\n",
       "         -2.96103030e-01,  7.45432675e-02, -2.67066032e-01,\n",
       "         -5.36442101e-01,  3.95744920e-01,  9.61231887e-01,\n",
       "          3.97043079e-02,  4.99653757e-01, -1.47725075e-01,\n",
       "         -1.15939307e+00,  7.07561597e-02,  3.96901965e-02,\n",
       "          5.15107572e-01,  1.03704691e+00, -8.27814564e-02,\n",
       "          3.62033039e-01, -1.75852084e+00,  1.34577858e+00],\n",
       "        [ 7.79152930e-01,  3.85624677e-01,  4.40516263e-01,\n",
       "         -1.92624144e-02, -9.59895700e-02, -2.54098892e-01,\n",
       "          7.74089634e-01,  7.52450168e-01, -6.44797981e-01,\n",
       "          1.08723271e+00,  3.60233545e-01,  8.98992956e-01,\n",
       "          9.92387652e-01,  1.06699300e+00, -2.51797855e-01,\n",
       "          2.78020054e-01,  5.07942796e-01, -6.63631380e-01,\n",
       "          4.81072754e-01, -6.01443909e-02, -2.66519263e-02,\n",
       "         -4.55281794e-01,  1.34048268e-01,  9.04269457e-01],\n",
       "        [-1.92714736e-01, -5.28333426e-01, -8.07048082e-02,\n",
       "          6.82042539e-01,  2.03524977e-01, -4.79391634e-01,\n",
       "          1.25583127e-01, -3.16259265e-01, -3.06595176e-01,\n",
       "         -2.78433114e-01, -9.95604396e-02, -2.47164547e-01,\n",
       "          3.18847775e-01, -5.46064615e-01,  3.74185219e-02,\n",
       "         -5.22939488e-02,  5.88213623e-01, -1.25943601e-01,\n",
       "         -8.81639242e-01,  5.20732343e-01, -3.38617146e-01,\n",
       "         -4.62047726e-01,  1.76146597e-01, -2.44497001e-01],\n",
       "        [-3.78803074e-01, -1.21428758e-01, -1.64936185e+00,\n",
       "          2.29712009e-01, -1.00204420e+00, -5.77246308e-01,\n",
       "          3.37219954e-01,  4.05849032e-02, -4.37074490e-02,\n",
       "         -8.75845253e-02,  1.14767313e+00, -1.04626036e+00,\n",
       "          1.15213656e+00, -1.10414967e-01,  5.46549976e-01,\n",
       "         -6.58379436e-01, -2.23923728e-01,  6.85482323e-01,\n",
       "         -1.94273338e-01, -4.42621797e-01,  9.91887033e-01,\n",
       "         -5.24750829e-01, -2.23245248e-01, -1.84081912e-01],\n",
       "        [ 1.05083215e+00,  5.51529169e-01,  4.32194948e-01,\n",
       "          3.73731047e-01,  2.00255126e-01,  1.41678751e+00,\n",
       "         -9.81471062e-01,  1.87987149e-01,  1.67638111e+00,\n",
       "         -1.16827977e+00,  9.37043726e-02,  1.16364121e+00,\n",
       "         -2.45255027e-02, -2.94934452e-01, -2.32826248e-01,\n",
       "          7.34053016e-01,  3.26225072e-01,  7.22436309e-01,\n",
       "         -1.48155853e-01, -7.48351216e-02,  2.09187299e-01,\n",
       "          2.04569474e-01,  3.89042385e-02, -1.65492725e+00],\n",
       "        [-9.33632106e-02,  1.93545505e-01, -5.83039582e-01,\n",
       "          6.28221333e-01,  8.06202646e-03,  1.60878360e-01,\n",
       "          6.79201543e-01, -1.05561590e+00, -1.83104023e-01,\n",
       "          6.61975205e-01, -3.70707452e-01, -5.83466828e-01,\n",
       "         -1.38096154e-01, -3.89885187e-01,  1.14505351e+00,\n",
       "         -3.62883896e-01,  5.94758213e-01, -1.54109204e+00,\n",
       "          2.64236778e-01,  7.86836088e-01,  3.69542778e-01,\n",
       "          3.57618362e-01,  1.49078127e-02, -1.12087059e+00],\n",
       "        [ 3.27507764e-01,  6.51397884e-01,  1.28923082e+00,\n",
       "          4.61337566e-01,  1.41928673e-01,  2.87585519e-02,\n",
       "         -2.83630639e-01, -4.78920847e-01, -1.00387394e+00,\n",
       "          4.45650011e-01, -5.87118566e-01, -6.93202972e-01,\n",
       "         -1.91126183e-01, -1.68876028e+00, -8.85512650e-01,\n",
       "         -1.34676290e+00,  3.91345918e-01,  1.00089872e+00,\n",
       "          7.03317285e-01, -9.50379312e-01, -2.31168485e+00,\n",
       "          1.65360838e-01, -6.95800960e-01,  7.56011531e-02],\n",
       "        [ 7.34008610e-01,  1.64569378e-01,  4.51572776e-01,\n",
       "         -4.85209435e-01,  5.98569274e-01,  5.74399710e-01,\n",
       "          8.46786380e-01,  1.16315521e-01,  7.92264223e-01,\n",
       "         -3.18701059e-01,  8.63281190e-02,  3.45112443e-01,\n",
       "          2.58938670e-02, -4.66403693e-01,  1.28360227e-01,\n",
       "         -3.51317390e-03, -7.88733363e-01, -4.44647491e-01,\n",
       "          6.63428485e-01,  7.61915207e-01,  5.51878568e-03,\n",
       "          4.92896557e-01,  7.57793844e-01,  1.15959764e+00],\n",
       "        [-7.85754621e-01, -1.46749113e-02, -2.61112571e-01,\n",
       "          2.28936344e-01, -8.79137576e-01, -6.69426322e-01,\n",
       "         -6.98658764e-01, -1.19357355e-01, -5.96373320e-01,\n",
       "         -2.01059699e-01, -6.98852316e-02,  3.80245268e-01,\n",
       "          5.99556938e-02,  3.38278040e-02,  3.31691325e-01,\n",
       "         -1.29017588e-02, -1.74547315e-01,  9.06824172e-01,\n",
       "          5.04174650e-01, -9.01634339e-03,  3.14620376e-01,\n",
       "          1.59773141e-01,  1.06605709e+00,  1.12296358e-01],\n",
       "        [ 5.50435603e-01, -1.22524448e-01,  3.49631190e-01,\n",
       "         -7.05329657e-01, -1.13902509e+00, -7.03462288e-02,\n",
       "          6.60624266e-01,  4.52442795e-01, -5.09146988e-01,\n",
       "          5.41814327e-01,  3.18762287e-02,  7.10904837e-01,\n",
       "          8.13695371e-01,  7.53491759e-01, -2.24468708e-02,\n",
       "          4.87701207e-01, -1.45992529e+00, -9.08899456e-02,\n",
       "         -3.72139990e-01,  1.13361490e+00, -1.00768828e+00,\n",
       "          7.35632926e-02, -1.28305876e+00, -2.26540804e-01],\n",
       "        [ 3.03004771e-01, -1.03820721e-03,  3.14261526e-01,\n",
       "          6.13299489e-01,  6.35801926e-02, -2.29206875e-01,\n",
       "          6.91504002e-01,  1.37952328e-01,  1.41440798e-02,\n",
       "          9.32732284e-01, -6.71201050e-02,  1.05089486e+00,\n",
       "          1.75574690e-01,  1.45270064e-01, -8.46815202e-03,\n",
       "          4.18182880e-01, -1.43826470e-01,  4.66497630e-01,\n",
       "         -6.49862364e-02,  4.65452485e-02,  2.04671741e-01,\n",
       "         -2.40163788e-01,  1.86415702e-01, -6.17832124e-01],\n",
       "        [ 1.45265967e-01, -3.67635012e-01, -2.23641351e-01,\n",
       "          3.57948571e-01,  5.03048480e-01, -1.33346096e-01,\n",
       "          7.14397430e-01,  1.00381851e+00,  7.40361363e-02,\n",
       "          6.00093186e-01,  3.83797884e-02, -1.27117425e-01,\n",
       "          9.47194576e-01,  8.47506106e-01,  9.58857536e-02,\n",
       "         -2.37675026e-01, -2.30304629e-01, -3.21226686e-01,\n",
       "         -1.70768976e+00, -6.15523636e-01,  4.31154579e-01,\n",
       "         -8.22568893e-01,  1.00024593e+00, -1.18102586e+00],\n",
       "        [ 4.40763980e-01,  4.64433581e-02, -1.04980819e-01,\n",
       "          4.79030490e-01, -1.36144117e-01, -7.47613013e-02,\n",
       "          5.96175313e-01, -9.90938485e-01,  4.45009530e-01,\n",
       "          6.96396768e-01,  2.89491825e-02,  4.52522039e-01,\n",
       "         -1.34180725e-01, -7.33969748e-01,  5.30413210e-01,\n",
       "          1.03480494e+00, -1.23330936e-01,  7.54482925e-01,\n",
       "          9.35493559e-02,  4.90005523e-01, -2.83926036e-02,\n",
       "          2.39932090e-01, -2.20568731e-01,  1.54915452e-01],\n",
       "        [ 1.21146822e+00,  5.43151081e-01, -8.38478506e-01,\n",
       "          7.41880417e-01, -1.38793722e-01,  9.59041715e-01,\n",
       "          1.64717421e-01,  4.89162624e-01,  1.64030075e-01,\n",
       "          2.87241906e-01,  1.19653426e-01, -7.46179700e-01,\n",
       "         -6.66608393e-01,  1.19555362e-01,  6.31388426e-01,\n",
       "         -6.84177652e-02,  2.03127876e-01, -5.62506318e-01,\n",
       "          9.67711881e-02,  5.39338946e-01, -5.03623784e-01,\n",
       "         -9.76200253e-02, -7.45783627e-01, -1.38058555e+00],\n",
       "        [ 5.28834939e-01, -1.92464602e+00, -4.92906153e-01,\n",
       "         -4.31071013e-01,  7.34986186e-01, -1.73860081e-02,\n",
       "         -6.51647210e-01, -5.63752413e-01,  6.56351745e-01,\n",
       "         -1.61539108e-01, -1.46460080e+00, -5.08097410e-01,\n",
       "         -1.13437593e+00, -3.45165208e-02, -4.28317517e-01,\n",
       "         -2.20651984e-01, -1.86909270e-02, -8.86779353e-02,\n",
       "          2.94093430e-01, -1.82117537e-01,  1.26502305e-01,\n",
       "         -5.85460067e-01,  1.82322025e-01,  1.16866097e-01],\n",
       "        [-1.84239130e-02, -2.44134116e+00, -5.25025129e-02,\n",
       "         -3.65811348e-01,  7.50348747e-01,  2.75801241e-01,\n",
       "         -1.27163839e+00, -7.78067648e-01,  5.07616341e-01,\n",
       "         -3.14896077e-01, -1.56330955e+00, -3.44745934e-01,\n",
       "         -5.95935225e-01, -3.23420048e-01, -4.62552279e-01,\n",
       "          1.13903917e-01,  2.32443009e-02, -1.39690533e-01,\n",
       "          3.01339418e-01, -3.35976124e-01,  5.14556229e-01,\n",
       "         -3.52499068e-01,  5.80309890e-02,  1.53353363e-01],\n",
       "        [-1.48967832e-01,  1.45298064e+00,  4.18996699e-02,\n",
       "         -7.80111015e-01,  6.19274557e-01,  1.02416980e+00,\n",
       "          1.01613367e+00,  3.29686105e-01,  8.24242651e-01,\n",
       "         -3.45943660e-01, -2.90200919e-01, -4.93270844e-01,\n",
       "          8.50323439e-02, -2.70637095e-01, -1.16114251e-01,\n",
       "         -5.90559840e-01, -4.60579544e-01, -5.26965976e-01,\n",
       "         -6.48674667e-02,  8.13012272e-02,  3.64726067e-01,\n",
       "         -2.40656704e-01,  2.00004995e-01, -1.05864860e-01],\n",
       "        [ 8.14875782e-01, -4.53194499e-01, -1.16335785e+00,\n",
       "          1.07035220e+00, -3.04813981e-01, -2.04806067e-02,\n",
       "         -7.62569606e-01,  7.18613505e-01,  3.09668422e-01,\n",
       "          4.97561902e-01,  5.58358192e-01, -6.97665215e-01,\n",
       "         -7.53981948e-01, -2.15708986e-01, -1.03838101e-01,\n",
       "          5.12999952e-01,  8.50431025e-01,  1.73036173e-01,\n",
       "          6.29235566e-01, -4.60564643e-01, -7.13786483e-01,\n",
       "          9.36190546e-01,  5.66655278e-01, -2.27070481e-01],\n",
       "        [ 2.25100309e-01,  5.10073543e-01,  1.46878555e-01,\n",
       "          4.80718315e-01,  3.86689126e-01,  2.28566423e-01,\n",
       "          4.18695360e-01,  1.68918407e+00,  1.13555706e+00,\n",
       "          6.33964464e-02, -3.88428599e-01,  2.86766231e-01,\n",
       "          8.01154494e-01,  1.47933722e+00, -9.95151103e-02,\n",
       "         -4.46161538e-01, -4.88488525e-01,  2.60867268e-01,\n",
       "         -3.24522376e-01,  7.37308264e-02,  2.08871201e-01,\n",
       "         -5.70951819e-01,  1.79337993e-01,  3.33728760e-01]], dtype=float32),\n",
       " array([-0.41936004, -0.6772003 , -0.4279914 , -0.6535075 ,  0.09425072,\n",
       "         0.03197696,  0.6659491 ,  0.45852947,  1.2976903 ,  0.35467935,\n",
       "         0.33611843,  0.18039352,  0.24441864,  0.32375544, -0.2381728 ,\n",
       "        -0.31813347,  0.31550315,  0.02679737, -0.32987386,  0.2223654 ,\n",
       "        -1.0066645 , -0.25278   ,  0.06345885, -0.30425766], dtype=float32),\n",
       " array([[-0.30547452,  0.06563308,  0.55954367],\n",
       "        [-1.100279  , -0.16358802,  0.6179631 ],\n",
       "        [-1.030776  ,  0.87460166,  0.2164663 ],\n",
       "        [ 0.71901304,  0.11942021, -0.9723028 ],\n",
       "        [ 0.60603374, -0.65927607,  0.20242327],\n",
       "        [ 0.8026099 , -0.2562112 , -0.8592354 ],\n",
       "        [ 0.7204735 ,  0.36878812, -0.8806633 ],\n",
       "        [ 0.34705535, -0.8865137 ,  0.7286597 ],\n",
       "        [-0.8987211 ,  0.6474281 ,  0.39656156],\n",
       "        [-0.6037314 ,  0.21860538,  0.74432015],\n",
       "        [-0.00477299,  0.5329067 , -0.66050303],\n",
       "        [ 1.1427543 , -0.6177425 , -0.75664365],\n",
       "        [-0.2936846 , -0.21816085,  0.59206176],\n",
       "        [-0.6684027 ,  0.65814966, -0.49474522],\n",
       "        [ 0.07742689, -0.5800762 ,  0.5133759 ],\n",
       "        [-0.65722376, -0.07740638,  0.4888524 ],\n",
       "        [-0.53847617, -0.10821343,  0.8205664 ],\n",
       "        [-0.53678733, -0.57779634,  0.20694183],\n",
       "        [ 0.4731372 ,  0.16740547, -0.9338216 ],\n",
       "        [-0.41432738,  0.11613005,  0.73845434],\n",
       "        [ 0.06989997, -0.84805554,  0.49502045],\n",
       "        [-0.2853205 , -0.38441843,  0.60191584],\n",
       "        [-0.5025967 ,  0.74899656, -0.00953638],\n",
       "        [-0.44633898, -0.5567356 ,  0.46868184]], dtype=float32),\n",
       " array([ 1.651404  ,  0.01859918, -1.258601  ], dtype=float32)]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = model.get_weights()\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 75        \n",
      "=================================================================\n",
      "Total params: 675\n",
      "Trainable params: 675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ANN Model - 3 Classes.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "new_model = load_model('ANN Model - 3 Classes.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 75        \n",
      "=================================================================\n",
      "Total params: 675\n",
      "Trainable params: 675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list:  [-0.0787127   0.45029786  0.52229671  1.25960831  0.48683742  0.15453361\n",
      "  0.77673743  3.65532532 -0.48185804 -0.46387797 -0.28492448  0.24426298\n",
      " -0.5257728  -0.98574422 -0.75830351  0.03761023 -0.3554718   0.2265692\n",
      "  0.28283899 -0.11854736 -0.16812285  0.59939552  0.2444506   0.27172375]\n"
     ]
    }
   ],
   "source": [
    "print(\"list: \",X_test[117:118][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.46470201,  0.45029786,  0.52229671, -1.55303726, -2.05407381,\n",
       "        -0.10955627, -1.28743635, -0.53543712, -0.48185804,  0.36118078,\n",
       "        -0.28492448, -0.1448675 ,  0.14106506,  0.19742374, -0.75830351,\n",
       "         2.25908338,  6.12608262, -0.52509922, -0.20251127, -0.07518573,\n",
       "        -0.08602796,  0.12758872,  0.2444506 ,  0.27172375]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = [[67, 1, 1, 20, 0, 1, 0, 0, 0, 21, 0, 15067, 0.32, 158, 0, 285, 281, 4, 0, 159, 137, 22, 1, 1]]\n",
    "check = sc.transform(check)\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93259376 0.01929214 0.0481142 ]\n",
      "[0 2 2 2 2 2 2 0 2 2]\n"
     ]
    }
   ],
   "source": [
    "y_pred = new_model.predict(X_test[117:127])\n",
    "print (y_pred[0])\n",
    "y_pred_class = np.argmax(y_pred,axis=1)\n",
    "print(y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.30547452,  0.06563308,  0.55954367],\n",
       "       [-1.100279  , -0.16358802,  0.6179631 ]], dtype=float32)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.get_weights()[2][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
